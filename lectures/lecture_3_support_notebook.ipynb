{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MLU Logo](https://drive.corp.amazon.com/view/bwernes@/MLU_Logo.png?download=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 3 Supporting Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "<p>\n",
    "<div class=\"lev1\">\n",
    "    <a href=\"#Gradient-Descent\">\n",
    "        <span class=\"toc-item-num\">1.&nbsp;&nbsp;</span>\n",
    "        Gradient Descent\n",
    "    </a>\n",
    "</div>\n",
    "<div class=\"lev1\">\n",
    "    <a href=\"#MC-Approximator\">\n",
    "        <span class=\"toc-item-num\">2.&nbsp;&nbsp;</span>\n",
    "        MC Approximator\n",
    "    </a>\n",
    "</div>\n",
    "<div class=\"lev1\">\n",
    "    <a href=\"#Multiple-Tiles-for-Multiple-Features\">\n",
    "        <span class=\"toc-item-num\">2.&nbsp;&nbsp;</span>\n",
    "        Multiple Tiles for Multiple Features\n",
    "    </a>\n",
    "</div>\n",
    "<div class=\"lev1\">\n",
    "    <a href=\"#TD(0)-Approximator\"><span class=\"toc-item-num\">4.&nbsp;&nbsp;</span>\n",
    "        TD(0) Approximator\n",
    "    </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ref. https://github.com/jcassiojr/Reinforcement-Learning-In-Motion/tree/master/Unit-8-The-Mountaincar\n",
    "\n",
    "This note book is based on the lectures from Phil tabor. Yopu can find his complete video course on O'reilly website. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run the command below the first time you start your instance\n",
    "! pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if \"../\" not in sys.path:\n",
    "    sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0, difference: -5.4\n",
      "Step: 1, difference: 0.023760000000000003\n",
      "Step: 2, difference: 0.025309273140264987\n",
      "Step: 3, difference: 0.026978303236479206\n",
      "Step: 4, difference: 0.028774389122137145\n",
      "Step: 5, difference: 0.030704171104943834\n",
      "Step: 6, difference: 0.03277313550751959\n",
      "Step: 7, difference: 0.03498495575728611\n",
      "Step: 8, difference: 0.03734063397888843\n",
      "Step: 9, difference: 0.03983740658234747\n",
      "Step: 10, difference: 0.04246738230109215\n",
      "Step: 11, difference: 0.04521589529960479\n",
      "Step: 12, difference: 0.04805958449122871\n",
      "Step: 13, difference: 0.05096425942090499\n",
      "Step: 14, difference: 0.05388268959034348\n",
      "Step: 15, difference: 0.05675256261424311\n",
      "Step: 16, difference: 0.0594949956770483\n",
      "Step: 17, difference: 0.06201414040877884\n",
      "Step: 18, difference: 0.06419855881437808\n",
      "Step: 19, difference: 0.06592510511101723\n",
      "Step: 20, difference: 0.0670659367382691\n",
      "Step: 21, difference: 0.06749890133771519\n",
      "Step: 22, difference: 0.06712084685040987\n",
      "Step: 23, difference: 0.06586242786245022\n",
      "Step: 24, difference: 0.06370195454962091\n",
      "Step: 25, difference: 0.06067515017798364\n",
      "Step: 26, difference: 0.05687780792099262\n",
      "Step: 27, difference: 0.052459541600431425\n",
      "Step: 28, difference: 0.04760893808460742\n",
      "Step: 29, difference: 0.0425327592882192\n",
      "Step: 30, difference: 0.03743347657569185\n",
      "Step: 31, difference: 0.032489662383209605\n",
      "Step: 32, difference: 0.027842570193437943\n",
      "Step: 33, difference: 0.02359021082166146\n",
      "Step: 34, difference: 0.019788249686815806\n",
      "Step: 35, difference: 0.016455764593524602\n",
      "Step: 36, difference: 0.013583516820820485\n",
      "Step: 37, difference: 0.01114270508347337\n",
      "Step: 38, difference: 0.009092831544628588\n",
      "Step: 39, difference: 0.007387993490493905\n",
      "Step: 40, difference: 0.005981442727957198\n",
      "Step: 41, difference: 0.004828577199806894\n",
      "Step: 42, difference: 0.003888674996867625\n",
      "Step: 43, difference: 0.0031257076070132506\n",
      "Step: 44, difference: 0.0025085316219675136\n",
      "Step: 45, difference: 0.0020106955609398014\n",
      "Step: 46, difference: 0.0016100341135731888\n",
      "Step: 47, difference: 0.0012881668940809554\n",
      "Step: 48, difference: 0.001029976118198661\n",
      "Step: 49, difference: 0.0008231069329518448\n",
      "Step: 50, difference: 0.0006575133265744881\n",
      "Step: 51, difference: 0.0005250591856875708\n",
      "Step: 52, difference: 0.0004191759761891234\n",
      "Step: 53, difference: 0.00033457398521496984\n",
      "Step: 54, difference: 0.0002670018118808848\n",
      "Step: 55, difference: 0.00021304795404430976\n",
      "Step: 56, difference: 0.00016997831815812603\n",
      "Step: 57, difference: 0.0001356038994284603\n",
      "Step: 58, difference: 0.00010817350395164738\n",
      "Step: 59, difference: 8.628707268698577e-05\n",
      "Step: 60, difference: 6.882584014755722e-05\n",
      "Step: 61, difference: 5.489617795584323e-05\n",
      "Step: 62, difference: 4.378451786646309e-05\n",
      "Step: 63, difference: 3.492121652826086e-05\n",
      "Step: 64, difference: 2.785161888896326e-05\n",
      "Step: 65, difference: 2.2212905597562838e-05\n",
      "Step: 66, difference: 1.7715580638455464e-05\n",
      "Step: 67, difference: 1.4128677038982573e-05\n",
      "Step: 68, difference: 1.126793890104949e-05\n",
      "Step: 69, difference: 8.986384145703852e-06\n",
      "Minimum at  2.2499646074278457\n"
     ]
    }
   ],
   "source": [
    "next_x = 6  # We start the search at x=6\n",
    "gamma = 0.01  # Step size multiplier\n",
    "precision = 0.00001  # Desired precision of result\n",
    "max_iters = 10000  # Maximum number of iterations\n",
    "\n",
    "# Derivative function\n",
    "def df(x):\n",
    "    return 4 * x ** 3 - 9 * x ** 2\n",
    "\n",
    "\n",
    "for _i in range(max_iters):\n",
    "    current_x = next_x\n",
    "    next_x = current_x - gamma * df(current_x)\n",
    "\n",
    "    step = next_x - current_x\n",
    "    print(\"Step: {}, difference: {}\".format(_i, step))\n",
    "    if abs(step) <= precision:\n",
    "        break\n",
    "\n",
    "print(\"Minimum at \", next_x)\n",
    "\n",
    "# The output for the above will be something like\n",
    "# \"Minimum at 2.2499646074278457\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"lev1\">\n",
    "    <a href=\"#Lecture-3-Supporting-Notebook\"><span class=\"toc-item-num\"></span>\n",
    "        TOP\n",
    "    </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MLU Logo](https://drive.corp.amazon.com/view/bwernes@/MLU_Logo.png?download=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MC Approximator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Approximator\n",
    "### The Mountain Car Problem\n",
    "<img src=\"../images/RL-lecture3-1.png\" alt=\"Drawing\" style=\"width: 300px;\">\n",
    "The Mountain Car is a classic reinforcement learning problem where the objective is to create an algorithm which learns to climb a steep hill to reach the goal marked by a flag. The car’s engine is not powerful enough to drive up the hill without a head start so the car must drive up the left hill to obtain enough momentum to scale the steeper hill to the right and reach the goal.<br/>\n",
    "\n",
    "+ When the problem begins the car is dropped into the valley and given an initial position and velocity as a vector. **This is the car’s state**.\n",
    "<img src=\"../images/RL-lecture3-2.png\" alt=\"Drawing\" style=\"width: 300px;\">\n",
    "+ The agent must tell the car to take one of three actions: \n",
    "<img src=\"../images/RL-lecture3-3.png\" alt=\"Drawing\" style=\"width: 200px;\">\n",
    "+ This action is sent to the Mountain Car environment algorithm which returns a new state (position and velocity) as well as a reward. \n",
    "+ For each step that the car does not reach the goal, located at position 0.5, the environment returns a **reward** of -1. \n",
    "+ Each episode finishes if the car reach the goal or accumulate a sum of -200 negative rewards.\n",
    "+ We will use these rewards in our MC approximation algorithm to solve the Mountain Car problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('MountainCar-v0') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State space:  Box(2,)\n",
      "Action space:  Discrete(3)\n"
     ]
    }
   ],
   "source": [
    "print(\"State space: \", env.observation_space)\n",
    "print(\"Action space: \", env.action_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that the state space represents a 2-dimensional box, so each state observation is a vector of 2 (float) values, and that the action space comprises three discrete actions.\n",
    "\n",
    "By default, the three actions are represented by the integers 0, 1 and 2. However, we don’t know what values the elements of the state vector can take. This can be found using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min car position and velocity:  [-1.2  -0.07]\n",
      "max car position and velocity:  [0.6  0.07]\n"
     ]
    }
   ],
   "source": [
    "print(\"min car position and velocity: \", env.observation_space.low)\n",
    "print(\"max car position and velocity: \", env.observation_space.high)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this, we can see that the first element of the state vector (representing the cart’s position) can take on any value in the range -1.2 to 0.6, while the second element (representing the cart’s velocity) can take on any value in the range -0.07 to 0.07."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class Model encapsulate the function that update the weights:\n",
    "\n",
    "$w_{t+1}=w_t+\\frac{\\alpha}{t}(G - \\hat V)$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    def __init__(self, alpha, stateSpace):\n",
    "        self.ALPHA = alpha\n",
    "        self.weights = {}\n",
    "        self.stateSpace = stateSpace\n",
    "        for state in stateSpace:\n",
    "            self.weights[state] = 0\n",
    "    # return the component weight for that particular state\n",
    "    def calculateV(self, state):\n",
    "        v = self.weights[state]\n",
    "        return v\n",
    "    # MC update\n",
    "    # to decrease alpha value we are multiplining in this case for 1/t\n",
    "    # to update the weights we pass the agent's estimate of the value function, G and the state\n",
    "    # The value of that state is just the weight, since we are using state aggregation\n",
    "    # increment the weights by alpha times G minus value\n",
    "    def updateWeights(self, G, state, t):\n",
    "        value = self.calculateV(state)\n",
    "        self.weights[state] += self.ALPHA/t*(G - value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just put continuous values into bins to have discrete values\n",
    "# the weight has one component for each bucket and the value of the state is that component\n",
    "# the gradient of the value function approx is one for the groups component and zero for the others\n",
    "# returns in which bin are pos and vel (state)\n",
    "def aggregateState(posBins, velBins, obs):\n",
    "    pos = int(np.digitize(obs[0], posBins))\n",
    "    vel = int(np.digitize(obs[1], velBins))\n",
    "    state = (pos, vel)\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the policy, depending on the velocity signal (bin 4 is the threshold between positive and negative)\n",
    "# keep increasing the direction of movement \n",
    "# receives the velocity. If the velocity is positive, the agent pushes to the right and vice-versa\n",
    "def policy(vel):\n",
    "    #_, velocity = state\n",
    "    # 0 - backward, 1 - none, 2 - forward\n",
    "    if vel < 4: \n",
    "        return 0\n",
    "    elif vel >= 4: \n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For alpha: 0.1\n",
      "episode: 0\n",
      "episode: 1000\n",
      "episode: 2000\n",
      "episode: 3000\n",
      "episode: 4000\n",
      "episode: 5000\n",
      "episode: 6000\n",
      "episode: 7000\n",
      "episode: 8000\n",
      "episode: 9000\n",
      "episode: 10000\n",
      "episode: 11000\n",
      "episode: 12000\n",
      "episode: 13000\n",
      "episode: 14000\n",
      "episode: 15000\n",
      "episode: 16000\n",
      "episode: 17000\n",
      "episode: 18000\n",
      "episode: 19000\n",
      "For alpha: 0.01\n",
      "episode: 0\n",
      "episode: 1000\n",
      "episode: 2000\n",
      "episode: 3000\n",
      "episode: 4000\n",
      "episode: 5000\n",
      "episode: 6000\n",
      "episode: 7000\n",
      "episode: 8000\n",
      "episode: 9000\n",
      "episode: 10000\n",
      "episode: 11000\n",
      "episode: 12000\n",
      "episode: 13000\n",
      "episode: 14000\n",
      "episode: 15000\n",
      "episode: 16000\n",
      "episode: 17000\n",
      "episode: 18000\n",
      "episode: 19000\n",
      "For alpha: 0.001\n",
      "episode: 0\n",
      "episode: 1000\n",
      "episode: 2000\n",
      "episode: 3000\n",
      "episode: 4000\n",
      "episode: 5000\n",
      "episode: 6000\n",
      "episode: 7000\n",
      "episode: 8000\n",
      "episode: 9000\n",
      "episode: 10000\n",
      "episode: 11000\n",
      "episode: 12000\n",
      "episode: 13000\n",
      "episode: 14000\n",
      "episode: 15000\n",
      "episode: 16000\n",
      "episode: 17000\n",
      "episode: 18000\n",
      "episode: 19000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl8AAAGiCAYAAADZW6NHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xd4VFX6wPHvmfShJoSWUEIJJASkSxUpogELoqAoLKAgCqvrb9VV7A0FXV1cVOwo7IorroCyKk1FUYMYxIK0IIQaEEgIJQmknN8f5yZMeiCTucnM+3meeZK5584978zcOfPOueeeq7TWCCGEEEIIz3DYHYAQQgghhC+R5EsIIYQQwoMk+RJCCCGE8CBJvoQQQgghPEiSLyGEEEIID5LkSwghhBDCg2xPvpRSFymlttkdR0mUUgOVUvvsjsMTlFKPKaX+bXccNYVSqoVS6qRSys/uWMri6c+XUuozpdSECq67Rik1uapj8hRpy6oHO9sypZRWSrWt4LpTlVKHrHakQSXrPamUal1K2USl1DeV2b6nKaV+U0oN9FBdY5VSKyu4rttey/NOvpRSyUqpTOtNz7+9VIHHFdo5tdZrtdbtzzeOcup6Ryk1oyq2bW1/hFLqJ6XUcaXUEaXUF0qpVlbZOTUAlWkclVKRSqkcpVSbEsqWKKWeO5/titJprfdorWtrrXOh+iYSVfn5KqW+YVrr+ZXdjlIqymor/N0RVzl1SVsmbZlHKaUCgH8Al1rtyNFzSdyKsrax071R2kdrHae1XuOhut7VWl/qjm2dy/dAZRu2K7XWqyu5jRrJ+pAsAK4BvgBqA5cCuZ6ORWu9Xyn1OfAn4DGXGMOA4UAPT8dUHSml/LXWOXbH4Y2UUgpQWus8u2M5T9KWSVvmSY2BYOA3uwPxZbZ+J2itz+sGJAOXlFLWFvgKSAeOAO9by78GNHAKOAlcDwwE9hXZ7t+AX6z13sLsqJ8BJ4DVQKjL+h8AB626vgbirOVTgGzgjFXXMmt5BPAhcBjYBfzFZVshwDtAGrDZimNfKc9xFPBTKWXxVr3ZVt0/W8tvArZYz2MncKu1vBaQCeRZ65+04nQA04HfgaPAIiCslDpvBH4vsmwasNHl/j+BvcBxYANwkUvZY8C/rf8LvSdF3+9ziauC+5IGbgOSgGPAy5gv8vzym63XLQ1YAbQ8h+f0X+DfVvnkEuoOAp4D9gCHgFeBEKvsPuB7wN+6PxXTWAYDUVbc/sBTmC+qLOu9e6kCz3ki8C0w23rOO4G+1vK9wB/ABJf162G+IA8Du4GHrPchyHp8R5d1G1r7U6Oi76X1Pt6D+XylA+8DwS7l9wIpwAFgsvUc25byHNZYz/1bq7621rLJVrkf8DymDdgF3J7/mrk8/knr8SeAlUC4VbbHWjf/89DnfPcvacukLfNwW9a2rLYFaGftD/n79xcl7U8V3RdLqLcB8LH12qzHfMa+cVk3BlgFpALbgOvO8flNw7TVJ6xttwG+s+pbBAS6rH8LsMOq62Mgwlr+CvBckW1/BNxVwnv0mLXdBVadvwE9XB7XDdholX2AadNmlBL/RM62u0eBGdYy19fnUut1SQfmWq/5ZJfHf2O9r2mYz90wq+ycvgeqqsF6D3jQ2rGDgf4l7SQlfTis7a7DNFKRmC+hH4Gu1ra+AB51Wf9moA5mR38Bl0YE0/jMcLnvwHxQHwECgdaYhuMyq3wWsBYIA5oDmyi9wWptvcizgUFA7SLlj2E1AC7LLsfsqAq4GMgAupXRSNxpvRbNrOf3GvBeKfGEWDuL62udAPyfy/1xmA+mP3A3pqEPPo8Gq8JxncMH+n9AfaAF5ssk3iobgfnwxlpxPwR8dw7PKRu42nrvQ0qoezamUQiz9qNlwEyX/eVrazvRmA9bV6ssiuKJRLHkroznPBHIwXyJ+WEagT2YxDMI0wCcyN+vMA3PR1aMUcB2YJJVNg94ymXbfwaWl/H5Wo/5QgzDfIHeZpXFW69fHODEJK3lJV97rPX9gQAKJ1+3Yb74mwGhmGSj6Gv2O+bLKMS6P6uk17cqb0hbJm2Ze9uy/CSorLYliiL7d9H96Xz3ReA/mGSlFtAR2I+VXFjL9mLaHX/MvngE6HAOz+8joC7mc38a+Nzah+phPu8TrHUHW9vuZr22LwJfW2UDrDiUdT8Uk7TnJ2eu79FjmP1zOKatnAmss8oCMT9G78S0P9dgfiyUlXzlAHdYzz8El+QLCMckkddY5XdivkNck69sTFLph/lBfsDleayhgt8DlW2wTmJ+deffbrHKFgCvA83K2jnLaLDGutz/EHjF5f4dwNJSYqpvbb9eKQ1WL2BPkcfcD7xt/b8T60vfuj+FUhosq7w3Zic/bO0c73D2y/IxijRYJTx+KXBnGY3EFmCIy/2m1htf4hcS8CbwuvV/tLUTNiqj/jSgc9F4S4klmbMfhnOKq4IfaNeGZBEw3fr/M6wkw7rvwDT0LSv4nL4uo16F+aXZxmVZH2CXy/0ozK+2LcD9RZZXNvlKcrnfydpeY5dlR4EumA/5GVwaSOBWYI31/yW49BRgftmNL+PzNc7l/rPAq9b/87C+HKz7bSk/+XqihGX5DdUXWD0iLnEWfc0ecimfxtmksdDrW5U3pC0Dacvc2Za1pZy2paT9u+j+VMK2y90XMW1FNhDjUvY0Z5OL64G1RR77Gi4/Airw/Pq53N8A3Ody/3ngBev/t4BnXcpqW7FFWa/PHmCAVXYL8EUp79FjwGqXsg5ApvX/AExy6Xqk5BvKTr6Kfm4murw+44EElzKFSRJdk68dLuVO6zVpYt1fQwW/Byp7tuPVWuv6Lrc3rOX3WkGvt85auPkct3vI5f/MEu7XBlBK+SmlZimlfldKHce8YWCy15K0BCKUUsfyb8ADmF+mYHoD9rqsv7usILXW67TW12mtGwIXYXaEB0tbXyk1TCm1TimVatU9vIxY8+Nd4hLrFky3ZuNS1p8PjFZKBWPGTKzQWv/hUv89SqktSql0a3v1yqm/0nFZZ7/lD2IeW8Y2D7r8n4H1Hlt1/dOlrlTMvhVZwefk+n4W1RDz4dngsv3l1nIAtNbJwJeYBuPlMrZ1Poru12itS9rXwzG/6lz3x91Yr4EVn1Mp1UspFYVJ2JaUUW9pr3XR/b+s164i61Rke6XF4mnSlklb5q62DCrQtpyHiuyLDTE9NqW99y2BXkX2m7FAk3OIo0L7NGYfLKhba30S84MyUptM5T/ADVbxjcC7ZdRZtJ0Itk7GiQD2W9vLV167VeE2y9pu0ZNHDrqUZ1j/nnO7VSVnEmmtD2IyWZRS/YHVSqmvtdY73FzVjZjDUpdgGqt6mF9AKj+UIuvvxfzyiC5leymYLvr8QZAtKhqI1voHpdRiTDdvsbqVUkGYX77jgY+01tlKqaVlxJof781a628rGMY3mORkBKZb/l6X+i+y7g8BftNa5ymlXF8rV6cwDUf+Y/0o3GhUOC6t9bAKxl6avZhDasU+mBV8TiW9rvmOYBqLOK31/pJWUEpdjvnF+jnwd0yPU0nKqqeyjmB+MbbEdOuD2Tf3A2itc5VSizAN2SHgf1rrE+dRTwrm8Eu+5hV4TFnP+3y2V5Hteoy0ZcXrlrasQsptW85VBffFw5jDas2BrdYy1/d+L/CV1nqoO2IqxwFMmwWAUqoW5lBx/uvxHrBSKTUL05M78jzqSAEilVLKJQFrjhnOUJoKt1nWiUTNSl/9nLZdSJXM86WUGq2Uyg84zQoo/yyoQ5jjw+5QB3PM+SjmA/Z0kfKida0HTiil7lNKhVi/NjsqpXpa5YuA+5VSoVb8d5RWsVKqv1LqFqVUI+t+DHAVZvxAft1RSqn81zgQc9z7MJCjlBqGGdfjGmsDpVQ9l2WvAk8ppVpadTRUSo0oLSZr51sAPIM5bLHMpbgO5kN5GPBXSj2COW5fku2YXxaXK3NK9ENW7OcVVyW9inlP4qy66imlRltl5/KcitHmzLw3gNku72OkUuoy6/9wzOGPycAE4Eql1PBSNldsv1bmtOPHKhpPGXHmYvbNp5RSdazX/S7MmKx8CzGHFMZa/5+PRcBNSqlYpZQTeLgSYedv707rNa2POYGhog5j2gx3tRXnRdqygrqlLTsH5bUtpShzfypnX8yvNxdYDDymlHIqpTpg2q58/wPaKaX+pJQKsG49lVKxVh0TlVLJ5/RkS/cepj3pYiXsTwPfW0cT0FpvxCSpb2J6No+dRx0JmJ7K25VS/tZ7d2ElYv4E6KSUutrqWfsz594rWKE2obLJ1zJVeG6c/EMdPYHvlVInMQMO79Rn5yB5DJhvdXleV8n6F2C6NfdjegTWFSl/C+hg1bXU2jGvwByW2cXZNz6/kXjc2t4uzJlX/yqj7mOYBupX63kuxxzqedYq/8D6e1Qp9aPVE/EXTKOYhvml+3H+xrTWWzE7604r3gjMGT0fY34dnLCeX68KvCYtMGfCnHZZvsKKcbv1HLMopftVa52OGX/zJua1PUXhrtfzieu8aK2XYBrg/yhzOGYTkP8LtMLPqQz3YQb0r7O2vxrIn6vpdcwv+0+11keBScCbquQJEf8JjFJKpSml5ljLmmPGX7nDHZj3YSemV2AhZowWAFrr763yCMw4uXOmtf4MmIM5jLmDs5+n06U+qGxvYD5Hv2DORvoU86VZ7hQGVnf+U8C31ueh93nGUFHSlklb5u62rKy2pSSPUfb+VNa+6Op2zGGwg5ixe2/nF1jv3aXAGEzP1EFM+5qfkLqtzdJm6paHMb2kKZgTNMYUWW0hprf3vH4waq3PYAbHT8Lsx+MwCeZ5tVla6yPAaMy+fxQzvizxHLZX0vdAifJH6Ash3Mj6hbpIa93X7ljOl/VreBMQpN0wF47VQ/Kq1rpluSsLITxOmZne79Rab7E7lvOllPoe0868Xe7K5W/LgUnWx2qtv6x0cC5sv7yQEN5Ia72vJiZeSqmRSqkgpVQo5hfxsvNNvKzDYcOtwwGRwKOUfSKAEMJGWutLa1ripZS6WCnVxGpnJgAXYHpGz3d7lyml6luHSh/AjCUs2hNdaZJ8CSFc3YqZj+p3zOHBqZXYlsIc/krDHHbcgpmXSggh3KU98DPmsOPdwCitdUolttcH0/4dAa7EnAmdWekoi5DDjkIIIYQQHiQ9X0IIIYQQHiTJlxBCCCGEB1XJJKvlCQ8P11FRUXZULYSwyYYNG45YM6jXaNJ+CeF73N1+2ZJ8RUVFkZiYaEfVQgibKKXKvMRNTSHtlxC+x93tlxx2FEIIIYTwIEm+hBBCCCE8SJIvIYQQQggPsmXMlxBCCOFLsrOz2bdvH1lZWXaHIsoQHBxMs2bNCAgIqNJ6JPkSQgghqti+ffuoU6cOUVFRKKXsDkeUQGvN0aNH2bdvH61atarSuuSwoxBCCFHFsrKyaNCggSRe1ZhSigYNGnikd1KSLyGEEMIDJPGq/jz1HknyJYQQQviwqKgojhw5Uul13CU1NZWhQ4cSHR3N0KFDSUtLK3G9+Ph46tevzxVXXOGRuNxJki8hhBBCVBuzZs1iyJAhJCUlMWTIEGbNmlXien/729/417/+5eHo3EOSLyGEEMIHXH311XTv3p24uDhef/31YuXJycnExMQwduxYYmNjGTVqFBkZGQXlL774It26daNTp05s3boVgPXr19OnTx+6du1K37592bZtW6Xj/Oijj5gwYQIAEyZMYOnSpSWuN2TIEOrUqVPp+uwgyZcQQgjhA+bNm8eGDRtITExkzpw5HD16tNg627ZtY9q0aWzZsoW6desyd+7cgrLw8HB+/PFHpk6dynPPPQdATEwMa9euZePGjTzxxBM88MADxbZ54sQJunTpUuJt8+bNxdY/dOgQTZs2BaBJkyYcOnTIXS9BteGWqSaUUvHAPwE/4E2tdcl9hEIIUQ1JGyY8buDA4suuuw6mTYOMDBg+vHj5xInmduQIjBpVuGzNmnKrnDNnDkuWLAFg7969JCUl0aBBg0LrNG/enH79+gEwbtw45syZwz333APANddcA0D37t1ZvHgxAOnp6UyYMIGkpCSUUmRnZxert06dOvz000/lxlcSpZRXnqhQ6eRLKeUHvAwMBfYBPyilPtZaF09nhRCimpE2TPiCNWvWsHr1ahISEnA6nQwcOLDEKRWKJjqu94OCggDw8/MjJycHgIcffphBgwaxZMkSkpOTGVhCUnnixAkuuuiiEuNauHAhHTp0KLSscePGpKSk0LRpU1JSUmjUqNE5PdeawB09XxcCO7TWOwGUUv8BRgDScAkhagJpw4TnldVT5XSWXR4eXqGeLlfp6emEhobidDrZunUr69atK3G9PXv2kJCQQJ8+fVi4cCH9+/cvd7uRkZEAvPPOOyWuc649X1dddRXz589n+vTpzJ8/nxEjRlT4sTWFO8Z8RQJ7Xe7vs5a5xT/nHubS+JOMGwdTp8J998GMGXDmjCn/5RdYvhy+/db8n5wMx46B1u6KQAjh5aqsDdMaTmfluWNTQlRKfHw8OTk5xMbGMn36dHr37l3ieu3bt+fll18mNjaWtLQ0pk6dWuZ27733Xu6//366du1a0BtWWdOnT2fVqlVER0ezevVqpk+fDkBiYiKTJ08uWO+iiy5i9OjRfP755zRr1owVK1a4pX5PULqSWYpSahQQr7WebN3/E9BLa317kfWmAFMAWrRo0X337t3lbjtn62Yibp3Lye1/pnFIe06ecHDiBJw+DdnZ4O9vErJXXy38uMBAyMoCpeCBB+CLLyAs7OwtMtIkcQA//QT160PLlmZ9IUTVUEpt0Fr3sDuOoirShp1P+wUQ2PBXmjfcxe+br3J/4KJG2bJlC7GxsXaHUabk5GSuuOIKNm3aZHcotirpvXJ3++WOw477geYu95tZywrRWr8OvA7Qo0ePCmV8/m2ieTP1dUbc9jIDOo/nnRHvWAP6TOIFJrkaPx5OnDC348dNcpafSIWFQb16cPgwbNsGqakQGno2+brvPli5Eho1gl694MILYcAAcxNC+IRy27Dzab8A/AKPc/JEQ3fEKITwIu5Ivn4AopVSrTAN1hjgRjdsFwICuKp2dx7ddYDHWUDPiJ7cfuHtuF5svHlzcyvNPfeYm6s8l6MAzz4LV18N339vbsuWwSWXwKpVpvyhh0xPWa9e0KkTVPGFzoUQnldlbVhQrYNkHOnsjk0JUeWioqJ8vtfLUyqdfGmtc5RStwMrMKdpz9Na/1bpyPL16MEjb89jw+uX89cVf6Vb0270bd63Upt0uIx069zZ3PIPax87ZnrHwIwrmzcPUlLM/ZAQ6NYNbr8dxowxPWzvvgsNG5rxj/m3+vXlEKYQNUVVtmHBtQ5xZHdjd2xKCOFF3DLPl9b6U+BTd2yrmJ49cbz0Ev+Oe5iH6rcirmFclVSTr359cwMzdmz/fti9+2zP2PffQ/68dIcOwaRJxbfx3HNw993mcRMnQoMGhW/Dh0NsLJw6BXv3mmWhoWcPpQohPKuq2rBatQ5x6EwdTp6E2rXdvXUhRE1V/b/uL74YZs2iXsPmvNj5RQAyszNxKAdB/kFVXr1SEBVlbtdfX7gsIgJ27TLz3R05YsaVHTliQgYz6D8nBzZvNgnb0aOQm2seFxsLP/wAgwad3V79+iYRmzfPjDlbtw6eftr0uOXfgoPhjjugdWvYuhU+/9yclVy7NtSpY/527Qq1apn6c3NNufTECeF5I7tqfgn8kLy8a+0ORQhRjVT/5Ktly7Oj44HTOacZ8M4AOjfuzBtXvmHrzLf+/mcTs5K0bw9r1569r7U5ISAw0NyPjTWHLfMTs/xb/qWq8nvGMjML366/3iRfCQnmEGhRv/xixqe9+aZJ1BwOk5TlJ2irV0OzZubvl19CkybQuPHZv23bgp+fO18pIXzTcy8+YXcIQohqqPonX2C6lLZvh379CPIPIr5NPDPWzqBnRE9u7XGr3dFVmFLmzMt8jRvDjWUM6x0yBDZuLL38xhvh8svNlShOnjS3EydMYgbQty/MmnV2ef7fWrVM+fffwzPPmN4xVydOmERt5kxYssScCRocbJLNkBB4+22z3jvvwPr1Zrm/v0nY6tUzJykA5I/bbNnybEIphC85k5nBwQPp1G/YlLp17Y5GiJJFRUWRmJhIeHh4pdZxl9TUVK6//nqSk5OJiopi0aJFhIaGFltv/vz5zJgxA4CHHnqo4GLcDz74IAsWLCAtLY2TJ09WebznRWvt8Vv37t31ObnrLq2Dg7U+c0ZrrXVObo4e9u9hOuCJAP3tnm/PbVuikNxcrQ8f1vrXX7VevVrrd989W/bqq1pfeqnWXbtqHRendfv2WnfseLZ86lStw8O1Dg3Vuk4drUNCtG7W7Gz5sGFam/4+rRs00LpbN61vu+1seUKC1hs3ap2WpnVeXtU/V2EvIFHb0N64+3Yu7deEOy7UoPU//lHx10l4p82bN9sdQqlatmypDx8+XOl13OVvf/ubnjlzptZa65kzZ+p777232DpHjx7VrVq10kePHtWpqam6VatWOjU1VWutdUJCgj5w4ICuVavWedVf0nvl7varZvR89expBjD99ht06YKfw493r3mXnm/05NpF17JhygYi6kTYHWWN5HCcPUuzY8fCZbfeam6lmTvX3Eozc6aZg233bnPlgd27zaHUfLfccrZ3zOEwY9Pi4+GDD8yyESPM2adO59lbnz7murNgevVycyEoyBzKDQyEDh3OztG2bJmZGiQw0Dy2Xj1zaLWEH1BCVIl6zjPgn8mBAyF2hyIEV199NXv37iUrK4s777yTKVOmFCpPTk4mPj6e7t278+OPPxIXF8eCBQtwOp0AvPjiiyxbtozs7Gw++OADYmJiWL9+PXfeeSdZWVmEhITw9ttv0759+0rF+dFHH7HGunzShAkTGDhwIM8880yhdVasWMHQoUMJCwsDYOjQoSxfvpwbbrih1Nn7q5OakXz1sCaVTUyELl0ACA0JZemYpUz6eBKZ2Zk2BidKkz+NR2kWLIDffzdJ2bFj5vBp27Zny+vUMWPkUlNh3z5T7nr48umnzSFSV5Mnm+RLa7iqhEnF77wTXnjBjJ1r3twkZK63sWNh9GhT17x5hacQadjQ3PLH7AlRnlr+wVA7hZSU1naHIgTz5s0jLCyMzMxMevbsybXXXkuDBg0KrbNt2zbeeust+vXrx80338zcuXO5x5osMzw8nB9//JG5c+fy3HPP8eabbxITE8PatWvx9/dn9erVPPDAA3z44YeFtnmuF9Y+dOgQTZs2BaBJkyYcOnSo2OP2799Pc5dJPps1a8b+/cXmd6+2akby1aaNORXwhx/Mt6ulY6OOrJu0DqUUWmtbB9+Lc9e1q7mV5t//Lvvx6enmMlNnzpjb6dOmFyzfhg1m2ZkzpsctPR2io01ZXp45cSE9/ext586z04ikpJiTFYp64QWTwO3YATfccDYpy58qZNw485x27TJj4/z8Ct+uvdbsznv3mpMd8qc2yb81aSLJnTcJCQiBOgfYv78lZgoxIYyB7wwstuy6uOuY1nMaGdkZDH93eLHyiV0mMrHLRI5kHGHUolGFytZMXFNunXPmzGHJkiUA7N27l6SkpGLJV/PmzenXrx8A48aNY86cOQXJ1zXXXANA9+7dWbx4MWAurD1hwgSSkpKsK9BkF6v3XC+s7Uop5ZXf7TUj+VLK9H4lJpZQpMjKyWLSx5MYHDWYSd1KmHhLeCWlzh5uLKmsW7fSH1urFrz8cunlrVrBH38Un0akrzW/b26uSbyOHIEtWyAtzSzr3dskX8nJ8OSTxbcbF2eSr8REsMaGFvLVV6bnbvFic2WG/KSsXj2T3D3/PLRoAZ99Znrminr5ZXOCxOLFsGiReUxAwNnbM8+YkylWrYJvvilcFhwMU6aYx/z2Gxw4YA7XhoScPezbooWpR2uZvqQinAFOqJPCgf15SPIl7LRmzRpWr15NQkICTqeTgQMHkpWVVWy9oomO6/0g69etn59fwUW0H374YQYNGsSSJUtITk5m4MCBxbZ5rj1fjRs3JiUlhaZNm5KSkkKjRo2KPS4yMrLg0CTAvn37Sqy7uqoZyReYAT7BwSUWBTgCOJJxhGmfTqNjo470atbLw8EJb+NwnD3MWJL27U0CVJpBg0yCkpdnkrL8W37PXHy8OeR67FjhW0yMKW/UCPr3P7v899/N40+fNuWpqWb+uKLyf3QeOWLOlM3JMcvyb089Zcq/+MJ8pIrKHwLy8svwyiuFy4KCzNBLMJMHv/CCjJ8rT7+uIxj724/06zsMkGuTibPK6qlyBjjLLA93hleop8tVeno6oaGhOJ1Otm7dyrp160pcb8+ePSQkJNCnTx8WLlxI//79y91uZGQkAO+8806J65xrz9dVV13F/PnzmT59OvPnz2fEiBHF1rnssst44IEHSEtLA2DlypXMnDmzwnXYzp2j9yt6O+ezHSvgaMZR3eqFVjri+Qh94PgBt29fCG+Tl2dOID51Sutjx7Q+dOhs2a5dWq9dq/WKFVovXar1woVaL1hwtnzRIq1Pnz63+vDBsx2FyGf32Y5ZWVk6Pj5ex8TE6BEjRuiLL75Yf/nll1rrs2cy7tq1S7dv316PHTtWx8TE6GuuuUafOnWq0Dpaa/3DDz/oiy++WGut9Xfffaejo6N1ly5d9IMPPqhbtmxZ6ViPHDmiBw8erNu2bauHDBmijx49WlDvpEmTCtZ76623dJs2bXSbNm30vHnzCpb/7W9/05GRkVoppSMjI/Wjjz56TvV74mxHZbbpWT169NCJJRxCLFNurhmh3br12Snki/j54M/0ndeXdg3a8dXEr6gbJBPrCFFdKKU2aK172B1HZZ1L+3X61HH27thB+ukYYuKcBXPsCd+zZcsWYmNj7Q6jTMnJyVxxxRU+f3Htkt4rd7dfjvJXqSYcDpg+3czsWYrOTTrz4XUfsv/4fnak7vBcbEIIUYKV/32G6Ofvo0cvJxs22B2NEKK6qDljvpQy83398EOZq8W3jWfnnTupHWiuYqvlLEghhE1CQmpDnQOAOYNWiOosKirK53u9PKXm9HyBOeNxyxZznZwy5CdeM9fO5M+f/hk7Dq0KIURIcF2obbIS+gWQAAAgAElEQVSuAwdsDkYIUW3UvOQrL6/sCx66OJZ1jFcSX+GJr+TitkIIz3PWqg8haQQEZEvPlxCiQM1LvsBMQlQBsy6ZxYTOE3jsq8d4NfHVKgxMCCGKC3HWBQX166VLz5cQokDNGfMFZvrvP/4offKlIpRSvHHlG2YOsE+m0dDZkGs7XFvFQQohhNGkVSeeC7yCwHuT6d4v3O5whBDVRM3q+YIKJ175AvwCWDR6Ef1b9CctK62KghJCiOLqN4ni7vuXccffehRcHUGI6iYqKoojR45Ueh13SU1NZejQoURHRzN06NCCiVSLmj9/PtHR0URHRzN//vyC5Rs2bKBTp060bduWv/zlLwXjvj/44APi4uJwOByc83RXblbzkq+EBBg1ykz7XUHOACdfTviSyd3MdSHP5J6pquiEEKKAzs1l2w+fsTFhO8uX2x2NEDXDrFmzGDJkCElJSQwZMoRZJVyOIzU1lccff5zvv/+e9evX8/jjjxckaVOnTuWNN94gKSmJpKQkllsfvo4dO7J48WIGDBjg0edTkpqXfJ04AR9+yLlOmuPnMNdVW/n7SmJeiuH31N+rIjohhCigc7KJ+XQ49z7yFcOGmQu8C2GXq6++mu7duxMXF8frr79erDw5OZmYmBjGjh1LbGwso0aNIiMjo6D8xRdfpFu3bnTq1ImtW7cCsH79evr06UPXrl3p27cv27Ztq3ScH330EROsi99OmDCBpUuXFltnxYoVDB06lLCwMEJDQxk6dCjLly8nJSWF48eP07t3b5RSjB8/vuDxsbGxtG/fvtLxuUPNS77yB92fZ5dh87rNST+dzmX/voxDJw+5MTAhhCjMERhEYA4EOg8CMteXsNe8efPYsGEDiYmJzJkzh6NHjxZbZ9u2bUybNo0tW7ZQt25d5s6dW1AWHh7Ojz/+yNSpU3nuuecAiImJYe3atWzcuJEnnniCBx54oNg2T5w4QZcuXUq8bS7hIrWHDh2iadOmADRp0oRDh4p/V+/fv5/mzZsX3G/WrBn79+9n//79NGvWrNjy6qZmDbgHCAszlxgqZ7LV0sQ2jOWTGz9hyIIhDHt3GGsmrpHLEAkhqoZSOHMg0Gka/5QUaNvW5phEtTBwYPFl110H06ZBRgYMH168fOJEcztyxIy+cbVmTfl1zpkzhyVLlgCwd+9ekpKSaNCgQaF1mjdvTr9+/QAYN24cc+bM4Z577gHgmmuuAaB79+4sXrwYMBfWnjBhAklJSSilyM7OLlbvuV5Y25VSyisnSq95PV9QoZnuy9K7WW/+O/q//HLoF0a+P5LTOafdGJwQQpwVkuvAEWLmmZDpJoRd1qxZw+rVq0lISODnn3+ma9euZGVlFVuvaKLjej8oKAgAPz8/cnJyAHj44YcZNGgQmzZtYtmyZSVu81x7vho3bkyK1U2ckpJCo0aNiq0TGRnJ3r17C+7v27ePyMhIIiMj2bdvX7Hl1U3N6/kC6NcPdu2CzEwICTmvTQyLHsbbI97mu73f4e+omS+DEKL6c+Y6cDjNl4EcdhT5yuqpcjrLLg8Pr1hPl6v09HRCQ0NxOp1s3bqVdevWlbjenj17SEhIoE+fPixcuJD+/fuXu9385OadUq69fK49X1dddRXz589n+vTpzJ8/nxEjRhRb57LLLuOBBx4oGGS/cuVKZs6cSVhYGHXr1mXdunX06tWLBQsWcMcdd1S4bk+pmT1fd9wB339/3olXvj91/hOvXPEKfg4/uQSREKJKPN1+GlOHjOeTT4ofKhLCU+Lj48nJySE2Npbp06fTu3fvEtdr3749L7/8MrGxsaSlpTF16tQyt3vvvfdy//3307Vr14LesMqaPn06q1atIjo6mtWrVzN9+nQAEhMTmTzZzFoQFhbGww8/TM+ePenZsyePPPIIYWFhAMydO5fJkyfTtm1b2rRpw7BhwwBYsmQJzZo1IyEhgcsvv5zLLrvMLfGeD2VH0tGjRw9t9xwbrn4++DMTlk7gv9f9l7ZhMiBDiKqglNqgte5hdxyVVd3aL1EzbNmyhdjYWLvDKFNycjJXXHGFz19cu6T3yt3tV83s+QKYMAHGjHHLpkJDQtmTvocx/x0j47+EEG6VlLiCX79dzLffwv/+Z3c0QojqoOYmXwBffQVu6LlrUa8F80bMY0PKBqavnu6GwIQQwrjzX2OZ9OF4Zs+Ge++1OxohShcVFeXzvV6eUnOTrx494OBBt50+dHXM1dze83Ze+P4Flm1b5pZtCiFEiAogk1wiIuRsRyGEUbOTL6jUlBNF/f3Sv9OlSRfm/zy//JWFEKICQlQgGY5cmjaF9HQzh5PwTXJiV/Xnqfeo5iZfXbqAn995z3RfkmD/YFaMW8H7o9532zaFEL7N6Qgi0y+PiAhzX6ab8E3BwcEcPXpUErBqTGvN0aNHCQ4OrvK6au4EVyEhZirgDh3cutlGtcxkbodOHmLVzlWMu2CcW7cvhPAtIX5BZPjlYV0thZQUaNPG3piE5zVr1ox9+/Zx+PBhu0MRZQgODi50eaKqUnOTL4A5c6ps0zO/mcmc7+cQUSeCwa0GV1k9QgjvNjF+OgP3baJPH/j5Z4iOtjsiYYeAgABatWpldxiimqi5hx3zpaVVySCKGYNn0K5BO8YuHssfp/5w+/aFEL6h6+CxjBw/kzp14IILKj03tBDCC9Ts5OvXX82Ftqtg8pzagbVZNHoRaZlpjF8ynjyd5/Y6hBDeb9+W71nx/lNkn8nirbdg5Uq7IxJC2K1mJ1/t20NgoFsH3bu6oPEFzL5sNit+X8HL61+ukjqEEN7to4+fJX7rQxw7up8nn4R//cvuiIQQdqvZY74CA6FzZ7dON1HUbT1uIyM7g7EXjK2yOoQQ3isksBZkQcaJVCIi2sjZjkKIGt7zBWa+rw0bIK9qDgsqpbi7792EhYRxJvcMJ06fqJJ6hBDeyRlYC4DMU8do2lQmWhVCeEPy1bMnnDgB27dXaTW5ebkMnj+Ymz66SeZpEUJUWEhwbQAyTh0jIkLm+RJCeEPyNWQIvPoqhIdXaTV+Dj9GtB/Bh1s+5Mmvn5QB+EKICnGG1AVM8tW0KRw7BpmZNgclhLBVzR7zBdCiBdx6q0equrvv3WxI2cCjax7lq91f8faIt2lRr4VH6hZC1Ezd+o/mM4cirvNQOvWG224DD0ygLYSoxmp+zxfA7t2wYkWVV+NQDt679j3euPIN1u9fz00f3VTldQoharYGLWKIH/MQoU2iqFfPzI6jlN1RCSHsVPN7vgBeeAFeew2OHwf/qn1KSikmd5vM4FaDycnLASAtM41cnUu4s2oPfQohap6TRw6wctkLdO89kjqN+/D883D11Wa4qhDCN3lHz1fPnmYQxebNHquydWhr2jVoB8Cdy++k49yO/G+7+yd7FULUbEd2b+HaPX/nizXvoDU8/TR8953dUQkh7OQdyVePHuZvFU22Wp57+t5D49qNufK9K7nl41tkOgohRIGQ2vUByDxzirAwMz2hnPEohG/zjuSrbVuoW7dKJ1stywWNL2D95PVM7zedeT/No/Ornfnp4E+2xCKEqF6ctcMAyDh9EqWQub6EEF6SfDkcpvfLpp4vgCD/IGZeMpOvJ35Nw1oNaVyrsW2xCCGqj5C6VvKVnQGY5Et6voTwbd6RfAHMmQNLltgdBf1a9GPdpHU0rdOUPJ3H1P9NJfGAfUmhEMJe/rXqEJALmTlmcq+ICDh61OaghBC28o6zHQHi4uyOoICyziNPPpbM0m1LeXXDqwxrO4z7+9/PRS0vsjk6IYRHORys6fUKzdt0A2DhQjPuSwjhu7yn5ys7G2bPhtWr7Y6kQOvQ1mz58xZmDJrBDwd+YMA7A+g/rz/7ju+zOzQhhAf1vfw2msdcCEBQkMzzJYSv857ky98fnnrK/KysRuoH1+fBAQ+y+/92Myd+Dg7lKBgPtvXI1oK5woQQ3mvp2/fxxUcvALBhA0yYIIPuhfBl3pN8KWXm+7Jx0H1ZnAFO7uh1B1/f9DUBfgGczjnN4PmDafdiO1754RWycrLsDlEIUUUe/GU2c9f+A4AjR2DBAti1y+aghBC28Z7kC8wZj7/9BhkZdkdSrgC/AF65/BUa1WrEtE+nEfVCFLO+mUV6VrrdoQkh3MyZ50+GPgOYsx1Ber6E8GXelXz17Al5ebBxo92RlMuhHIyIGUHCpAS+nPAlnZt05v7P72f9/vV2hyaEcDOn9idTZwPmbEeQ6SaE8GXec7YjQNeu4OcHO3dCv352R1MhSikGRg1kYNRANv2xibiG5qzN5797ngbOBozvPB6H8q4cWQhfE4I/xzDJV4MGEBAgPV9C+DLv+lZv1swccvzTn+yO5Lx0bNQRpRR5Oo//Jf2Pmz66iV5v9uK7vXIhOCFqMqcKJEOZk2uUguhoyM21OSghhG28q+dLKa+YQMehHHw+/nPe+/U97lt9H/3m9ePGTjfy7CXPElk30u7whBDnaPbk/5Krz2Zbv/1mYzBCCNt5V88XwNtvw6RJdkdRaQ7lYOwFY9l2+zYeHvAwH2/7mLSsNLvDEkKch5ad+tP6govtDkMIUU14X/KVlGTO487OtjsSt6gVWIsnBj3Bvr/uo2OjjgDcveJu/rPpP2itbY5OCFER33z0Ii/9Y0zB/fnz4aqrbAxICGGrSiVfSqnRSqnflFJ5Sqke7gqqUtq1g5wcSE62OxK3qhdcDzAX512zew03fHgDF719kVw3UogaYNl373BP2vsF9/ftg2XLIEum9xPCJ1W252sTcA3wtRticY/oaPM3KcneOKqIM8DJ+snrefPKN0lKTeLCNy7klo9v4UzuGbtDE0KUIiQgmNP+kKfzAJluQghfV6nkS2u9RWu9zV3BuEW7dubv9u32xlGF/Bx+TOo2ie23b+euPnfx8faP2ZO+x+6whBClcPo7Acg8fQo4O9GqJF9C+CbvG/MVHg4dOtgdhUfUC67Hc5c+x7bbt9E2rC2AjAMTohpyBljJ10lz0kx+z5fM9SWEbyp3qgml1GqgSQlFD2qtP6poRUqpKcAUgBYtWlQ4wHOmlM+dx10/uD5aax784kFSM1N55fJXUErZHZYQwhIS6IQcyDx5DMJbEBEBMTHg8L6fv0KICig3+dJaX+KOirTWrwOvA/To0UO6Z6qA1prXNryGM8DJ85c+LwmYENXEdTc9x2VH76JJZHvAdNBv2WJzUEII23jXJKv5/vMfmDEDEhMhONjuaDxCKcXTQ54mIzuD2etmUyugFk8OftLusIQQQJ3wSOqEywTJQgijslNNjFRK7QP6AJ8opVa4J6xK0tocevz9d7sj8SilFLPjZzOp6yRmrJ3BrG9m2R2SEAJI3vglTzw+mN3bfyhYNm0a3HyzjUEJIWxTqZ4vrfUSYImbYnGf/Okmtm+HuDh7Y/Ewh3Lw2hWvkZOXQ1T9KLvDEUIAe5ISeZQv6Ze0jpbtegLmTEcvnRFHCFEO7zzs6OVzfZXHz+HHO1e/U3D/wIkDRNSJsC8gIXycM6QuABkZ6QXLIiLg6+ozQ6IQwoO881ybevWgUSOvnuuror5K/orW/2zNwl8X2h2KED7L6TRXqMjMOlmwrGlTSE2VWe6F8EXemXwBjBwJrVvbHYXtekb2pHez3oxfMp4lW6rfEWIhfEFI7foAZJ4+m3zlz/V18KAdEQkh7OS9yderr8IDD9gdhe2cAU6W3bCMnpE9uf6/17N8x3K7QxLC5zhrhQKQkXWiYFm7dnDJJeZStEII3+KdY77y5c/27uPzXdUJqsNnYz9j0PxBjHx/JBtv3UhMeIzdYQnhMxrGdCP11l3UDm1csKx/f1i1ysaghBC28d7k6/PP4Zpr4MsvoVs3u6OxXf3g+qwct5L5P8+nfYP2aK0Z/cFomtZuSsv6LWlRrwUt67UkukE0YSFhdocrhNsopUYDjwGxwIVa60SXsvuBSUAu8BetdZVMl+PwDyC0SVRVbFoIUQN5b/LVsCEcP27OeJTkC4CGtRpyT997ADh55iTbj25n1c5VHD99vGCdBy96kBmDZ5CWmcboD0bTsl5L2oS1YXK3yTSq1ciu0IWojE3ANcBrrguVUh2AMUAcEAGsVkq101rnuj2C3FweeKQffToN58oxjwCmY75DBxgzBh591O01CiGqMe9NvtqaC0376nQT5akdWJtfpv4CQHpWOrvTd7P72G5ah5qTFI6fPs7JMyf5bMdnpJxMYfa62cwdPpfRcaPtDFuIc6a13gKUdLmtEcB/tNangV1KqR3AhUCC24NwOHhJf0/mFs2VmORLKTh1CnbtcnttQohqznuTL6cTmjWT6SYqoF5wPS4IvoALGl9QsKxl/Zasm7wOgM2HNzNh6QRuXHwjPSJ60Cq0lV2hCuFOkcA6l/v7rGXupxTObMhUheeVaNrUTLYqhPAt3pt8gZlsVXq+Kq1Dww4kTEogYW9CQeKVeCCRHhE9bI5MCEMptRpoUkLRg1rrj9yw/SnAFIAWLVqc1zZCch1k5BZOviIiYMeOykYnhKhpvDv5GjPGzGIoKs3f4c9FLS8C4MtdXzJ4wWDGdBzDS8NeooGzgc3RCV+ntb7kPB62H2jucr+Ztayk7b8OvA7Qo0cPfR514cxzkJl3ptCypk1llnshfJH3zvMFMGUKTJ9udxRep3+L/jw56Ek+3PwhcXPjWLp1qd0hCXE+PgbGKKWClFKtgGhgfVVVFpLnR5YunHxddBGMGAF5eVVVqxCiOvLu5AvMGY+nTtkdhVcJ8AvgoQEPkTglkaZ1mjLy/ZFM+2Sa3WEJUSKl1Eil1D6gD/CJUmoFgNb6N2ARsBlYDvy5Ss50tKx77hjL/l64Y+2GG2DePHB4f0sshHDh3R/57dvNdR4XL7Y7Eq90QeMLWD95PY9d/BgXRl4IgNbndURGiCqjtV6itW6mtQ7SWjfWWl/mUvaU1rqN1rq91vqzqozDPzC4lPggt8pSPiFEdeTdyVdUlPlJKYPuq0yAXwCPDnyUiV0mAvDGj28wfsl4UjNlrJ0Qrl7/+xgefXJIoWWbN0NwMCyVI/dC+BTvTr4CA00CJtNNeExaZhoLf11IzEsx/Ovnf0lPmBCWL/eu5b3j3xZaFh4OZ87IdBNC+BrvTr5AppvwsPv638eGKRtoE9aG8UvHM3jBYLYd2WZ3WELYzukIJMNR+PhieDj4+8OBAzYFJYSwhfcnX+3amZ4v6YHxmM5NOvPtzd/y2hWv8fPBn9mTvsfukISwXYgjiExH4dMaHQ5o0kR6voTwNd49zxfA6NEQG2tGtPp7/9OtLhzKwZTuUxjTcQx1g+oCMDthNrENY4lvG29zdEJ4XohfEJl+xeeUiIiQni8hfI33ZyMXXWRuwhb5ideZ3DO8/dPb/PrHr4zuMJoX4l8gok6EzdEJ4Tl1A+sQmKfQWhe6zuT48eY6j0II3+H9hx3z8swpRbt32x2JTwv0C+SHW37gyUFPsmz7MmJeiuHF718kN0/OsRe+4eGnvuHY03nFLvD95z/DNJkmTwif4v3Jl9bQpQvMnWt3JD4vyD+IhwY8xKapm+jTvA93r7yb39N+tzssIWyVlweHD8tcX0L4Eu9Pvvz8oG1bOeOxGmkT1oblY5fz460/0q5BOwBeTXyVw6cO2xyZEFXnq0XPcv1dzTl8OLnQ8rffhkaNYN8+e+ISQnie9ydfYKabkLm+qhWlFB0bdQRgR+oObv/0dqJfjOYfCf/gTO6Zch4tRM2zb99mFtXbR1pq4dH1TZuavzLoXgjf4RvJV7t2sGOHXL22mmob1pZfp/5K3+Z9uXvl3cTNjePjbR/LBK3Cq4QE1wYg89SxQssjrPNOZLoJIXyHbyRf0dFw+jTs3Wt3JKIUsQ1j+XTsp3x646f4O/yZuHQix08ftzssIdzGGVQHgIwiyZf0fAnhe3wj+YqPh48/hgYN7I5ElGNY9DB+ue0X1kxcQ73geuTm5fLkV0/yx6k/7A5NiEoJCTbJV2ZG4R8VDRuaoanS8yWE7/CN5KtFC7jySqhd2+5IRAUE+AVwQeMLAPjhwA88/tXjRL8YzfPfPS/jwUSNVbdeIyJPOlBFjqY7HPDMM3DppfbEJYTwPGXHuJoePXroxMREz1b65ZdmhnuZcLXG2XJ4C/esuodPkz6lbVhbnhv6HFe1v6rYfEmielNKbdBa97A7jsqypf0SQtjK3e2Xb/R8Afz1rzBrlt1RiPMQ2zCWT278hM/GfkaAI4B7V99LTl4OAKfOnLI5OiEqLzUVtm61OwohhKf4TvLVrp3M9VXDxbeN55epv7B87HIC/AI4deYUkf+I5LJ/X8aCnxdw4vQJu0MUolTHdm7m8r82Ytl/nypW9uCD0ikvhC/xneQrOhp27oTsbLsjEZXg7/CnVWgrwFwv8vYLb2f70e1MWDqBRs814vr/Xs+mPzbZHKUQJcjJ4dP6h9mxv/j+2bQpHDkCZ2RIoxA+wXeSr3btzPU7kpPtjkS4SWhIKDMGz2DnX3by7c3fcnOXm/l85+dk55oE+7c/fmPt7rXkaZnfTdjPWScMgIwzJ4uV5c/1dfCgJyMSQtjFd5Kv6GjzV2a69zpKKfo278vLl79Myt0pdGnSBYAX1r3AgHcG0PqfrXlszWOkZqbaHKnwZQG16uLIg8zszGJl+cmXzPUlhG/wneSrSxfYuBEGD7Y7ElGFAvwCCs6CnB0/m3+N/Bcx4TE8/tXjRL0Qxcy1M22OUPgq5XQSkgMZ2RnFyvInWpW5voTwDb6TfDmdJgELCbE7EuEhtQNrM+6CcSwft5xfbvuF+LbxnMo2Z0dqraUnTHiWvz+djofQIDi0WFGbNvDmm9C1qw1xCSE8zt/uADxq2TIzqOKWW+yORHhYp8adWDR6UcH1Ij9J+oQbPryBOy68g7v63EW4M9zmCIUvSHixeK8XQN26MGmSh4MRQtjGd3q+AN5/H2bMsDsKYaP8Q5LRYdFc0e4KZn0zi6gXopi+ejqHTx22OTrhy375BX7+2e4ohBCe4FvJV7t25uLamcUHvArf0j68Pe9d+x6bpm3iqvZX8ey3z3LxOxdjxxUfhO+Y8tc23PVYnxLLJk2C6dM9HJAQwha+ddgxOhq0ht9/h44d7Y5GVAMdGnZg4bULeXjAw+w/sR+lFKdzTvPgFw/SvkF7YsJjiG0YK4clhVtszk4h6FTJkwFHRMhMOEL4Ct9Kvtq1M3+TkiT5EoXENowltmEsAGv3rOXlH14mKyeroLxBSAMWjFzA8OjhpJxIYUPKBmLCY4iqH4W/w7c+RuL8heDPKV3yRM9Nm8J333k4ICGELXzrWyN/rq+dO+2NQ1Rrl7S+hFMPnGJP+h62HtlacIuqHwXA57s+509L/gRAoF8g0WHRdGrciRmDZtAmrI2NkYvqzkkAh1XJ09hHRJyd5T4w0MOBCSE8yreSr7p1TevWoIHdkYhqzqEcRNWPIqp+FPFt4wuVjWg/goRJCYUSs2/3fEu94HoAfLf3O/wd/vSM6FkwwF8IgBAVSKYq+YzH/Lm+Dh6EFi08GJQQwuN8K/kCSbxEpdUJqkPvZr3p3ax3wTKtdUGi9ciXj/D5rs+JCY9hQucJjLtgHM3qNrMrXFGNxNZuxZnc/SWWxcfD8uUQLsMLhfB6vnW2I8DHH8Ntt9kdhfAyrj1cH173IW9c+QbhznDu//x+Wsxuwf8t/z8boxPVxaMzv2Pxs7tLLGveHC67zMwHLYTwbr6XfG3eDK+9BseP2x2J8FL1gusxudtk1t60lh137OCRix+hV2QvANKz0pn00SRW/b6KXWm7SM9Kl+ktBAA5ObB0KWzaZHckQoiq5nuHHfMH3e/YAd262RuL8Hptwtrw2MDHCu7/fOhnPtj8AfN+mlewzE/5sepPqxjUahBrktfw9+/+TlhIGGHBYeZvSBjXd7yeRrUa2fAMhDu9+vQ1vJS2nF+fPVVsPKBSMGqUmetL5oIWwrv5bvKVlCTJl/C4AS0HcPCeg6xJXsMfp/4gNTOV1MxUWoe2BsxFlw+dPMSWw1tIzUwl/XQ6AINbDaZRrUYs3rKYz5I+45LWlzCk9RCZf6yGSTt5hN9qZ3I69zTB/sGFyvz8oHFjOHDApuCEEB7je8lX27bm7/bt9sYhfJYzwMnw6OEllg2PHl6oLCcvh2NZx6gfXB+A5GPJfLD5A97c+CYKRdemXRnaeihPDX4KP4efR+IX588ZEAJAxplTxZIvMNNN7Nvn6aiEEJ7me2O+nE4z2apcYkjUAP4Of8Kd4QUTud7V5y6O3HuEhEkJPDHoCWoH1mbF7ysKEq/H1zzOs98+y8aUjeTm5doZuihBSIAZTZ95Mq3E8nbtYOtWT0YkhLCD7/V8gWndZP4lUUP5O/wLprp4aMBDBUmW1ppVO1fx7d5vuY/7cAY46dy4Mzd2upHbL7wdgOzcbAL8AuwM36eFBNWCDMg4mQYlDOHr2BEWLjTnA9Wt6/n4hBCe4ZvJlyRewovk93oppfjm5m9IOZHC57s+J/FAIhsPbiQ1MxWAzOxMwp4No12DdnRt0tXcmpq/dYLq2PkUfEaLyDguXd+AAEfJCfDEiTByJNSq5dm4hBCepew4zb1Hjx46MTHR4/UWWLnSnE60dCmEhdkXhxAedCzrGH//9u9sPLiRjQc3cvDkQQCev/R57upzF1k5WexM20mHhh2qpH6l1AatdY8q2bgH2d5+CSE8zt3tl2/2fJ0+DWvXmkH3vXuXv74QXqB+cH2eGvJUwf2DJw+yMWUjMeExACz6bRETlk5gcKvB3HHhHVzR7gq5aLgN5s0zhxxHjbI7EiFEVfG9AfdgRrWCmW5CCB/VpHYThkUPo1VoKwCGtR3GzCEzSTqaxMj3R9JmThue+eYZsnOzbY7Ue/zy6du0/Js/q1e8Uuo6r7xi5oEWQngv30y+WrUCh0OmmxDCRcNaDZnefzo779zJ4usW0ya0De9tej9EOBsAACAASURBVK+g9+vACZmAqrJUXh57audy7Pgfpa4TFwe//ebBoIQQHuebyVdgoEnApOdLiGL8Hf6MjB3JFxO+4Jubv0EpRXpWOu1fak/ft/ry3q/vcSb3jN1h1kghznoAZGadKHWdjh0hJQVSUz0VlRDC03wz+QIYPNhMJy2EKFXtwNqAScieHPQkhzMOc+PiG2kxuwVbDm+xObqax1nLTJabUUbyFRdn/krvlxDey3dH077+ut0RCFFj1Aqsxf/1/j/+0usvrNixgvc2vUd0g2i7w6pxQmqb5Cvz9KlS1+nY0fzduRMuusgTUQkhPM13ky8hxDlzKAfDoocxLHqY3aHUSLXCIxiZHkHruJhS12nWzEyyWkemXhPCa1XqsKNS6u9Kqa1KqV+UUkuUUvXdFViV27DBjPtau9buSIQQPiKwcQSL/7Gfq0Y9VOo6SkniJYS3q+yYr1VAR631BcB24P7Kh+QhYWGQnAzbttkdiRBCFLJ0KYwbZ3cUQoiqUqnkS2u9UmudY91dBzSrfEge0qKFOetRzngUQniK1sT8nx9/faJfmaslJ8O778Ifpc9IIYSowdx5tuPNwGdu3F7V8vODNm1kri8hhOcoRYYjj2Nnjpe5Wv6g+02bPBCTEMLjyk2+lFKrlVKbSriNcFnnQSAHeLeM7UxRSiUqpRIPHz7snugrq1076fkSQniUM9dBRm5WmevIdBNCeLdyz3bUWl9SVrlSaiJwBTBEl3GVbq3168DrYC5Me25hVpHhw2HzZrujEEL4kJA8PzLzTpe5TpMmEBoqPV9CeKtKTTWhlIoH7gUu1lpnuCckD5oyxe4IhBA+JkT7kaHLvkKAUtC3r7kKmhDC+1R2nq+XgCBglVIKYJ3W+rZKR+VJubmQkwNBQXZHIoTwAVeF9savXmi56/3vfx4IRghhi0olX1rrtu4KxBZ//AHNm8M//gF//rPd0QghfMD0J7+0OwQhhM18u1O7YUNwOuHnn+2ORAjhQ3ReXrnrbNsGPXrAF194ICAhhEf5dvKlFPTqBQkJdkcihPARt9wRRdT9IeWuFxZmLsTx008eCEoI4VG+nXwB9OljzudOT7c7EiGEDwhQfmQ4cstdr2FDaNRIppsQwhtJ8tWnD2gN69fbHYkQwgeEOILI9Cv/sCOYyVZlugkhvI8kX716wRNPQOvWdkcihPABTv9gMvw1ZUyLWCAuzkxFWIFVhRA1SGWnmqj56tWDhx+2OwohhI8I8Q9GKziTe4Yg/7KnuBkwAA4ehJMnoU4dDwUohKhy0vMFZrzXihVQgTOQhBCiMnp3HMZd2T3QlN+dNWoULFokiZcQ3kaSL4DFiyE+Xi6yLYSocoPHPczzM34g2D+4wo/Jzq7CgIQQHifJF0Dv3uavTDkhhKhiudlnOHH0ALk5FcuouneHSZOqOCghhEdJ8gXQvj3Ury/JlxCiyi15cRp1X4pkS9J3FVo/PFymmxDC20jyBebqtb17S/IlhKhyIUG1AMg4daxC6+ef8Zhb/tRgQogaQpKvfDLZqhDCA5zBZvR8ZkbF2pqOHSErC3btqsqohBCeJMlXvptugh9/hNq17Y5ECOHFQqzkK+NUxZKvuDjzVyZbFcJ7yDxf+Zo3NzchhKhCTmc9ADKzTlRo/bg4uPNOaNmyKqMSQniS9Hy5+v/27js8yirt4/j3pM8kEELvIIogHUQEC4ogdlHXhop1wQL2Luq6tlVcxV5wxbVgV8TXZV1AsFMERJqKoCBNiAIhJJN+3j9OYgJSEjIzz5Tf57rmmpZ55p4MnNzPKff573/hqae8jkJEYlizDgdyR9nh7N/2wGr9fEYGPPoo9OwZ4sBEJGyUfFU1cSLcfruKrYpIyDTqdBB3//0zuvQ8ptqvKSxUGUKRWKLkq6p+/WDLFvjhB68jEZEYZUtK+PWnhWzdtL7ar7nzTujaFUpKQhiYiISNkq+q+vVz1yo5ISIhUrhyOc1e6c7Tr1xV7dd06QJFRbB8eQgDE5GwUfJV1f77Q1aWki+RGGKMecgY870xZqExZqIxpl6V5241xiw3xvxgjKn+OGAtpKZnYiwEivKr/RqteBSJLUq+qqootqqCOiKxZCrQxVrbDVgG3ApgjOkEnA10Bo4FnjbGJIY6GJOeTloJ5BdXP/k64AAwRpXuRWKFSk3s6J13wO/3OgoRCRJr7ZQqd2cBp5ffHgK8Ya0tBH42xiwH+gCh7fr2+fAXQ6AkUJOXsO++6vkSiRVKvnakxEskll0MvFl+uwUuGauwpvyx0EpOxlcM+TVIvgDGjIFGjUIUk4iElZKvHZWVwXnnwSGHwKhRXkcjItVgjJkGNN3JU6OttZPKf2Y0UAJM2IvjjwBGALRu3boWkTp3ND6d1h0PrtFrTj211m8rIhFCydeOEhJg0SLYtEnJl0iUsNYO2t3zxpgLgROBgdZaW/7wWqDqthYtyx/b2fHHAeMAevfubXf2MzUx4pa3a/ya3Fz44gvo1QuaNKltBCLiJU2435l+/WDWLBVbFYkBxphjgZuAk621VWe5fwCcbYxJNcbsA7QH5oQjpjVLZ7Hyu5pNLfv5Zzj+eJg+PURBiUjYKPnamX79ICcHvv/e60hEpPaeBOoAU40xC4wxzwJYa5cAbwFLgY+Akdba0nAEdMGTAxn24sk1ek2HDpCYqBWPIrFAw447U7XYaqdO3sYiIrVird1vN8/dB9wXxnAA8NkktlBUo9ekpkL79lrxKBIL1PO1M/vvD/37Q1qa15GISAzyk0yAmu8V1KWLer5EYoF6vnYmIQE+/dTrKEQkRvlMCvkJ22r8us6d4d13IT9fVXFEopl6vnantFQ72YpI0PkTUgiYmk8vu/hiWLDADUGKSPRS8rUr8+ZBvXpaWiQiQXfuEVfy8H5X1Ph1rVtDt25u4r2IRC8NO+5K+/aQl+cm3Q8e7HU0IhJDDjvjeg7by9e+/DLUrw8nnhjUkEQkjNTztSt167rZrTNDu82biMSfDT9+w6ypL1JaVvOhx3/+E559NgRBiUjYKPnaHRVbFZEQeG38dfT76mK2Fe3dpHuteBSJbkq+dkfFVkUkBHzJPgACxfl7+Mk/69IFVq6EbTXP20QkQij52p0BA+COO6BOHa8jEZEY4ktxdSLy87fU+LWdO7vrpUuDGZGIhJOSr91p0wbuvhtatdrzz4qIVJM/NQOAwLa9T76WLQtmRCISTlrtuCfbtsGiRZVbDomI1JIvJR3yIX8vkq9994XffoMGDUIQmIiEhXq+9mTsWDjkENhS80ZSRGRnDjzqPN5ofhXtWnSu8WsTEpR4iUQ7JV97UtHjNXu2t3GISMxo1rUfZw1/jAYNW+/V699/H4YPD3JQIhI2Sr72pE8fMEb1vkQkaPI2ruHjdx/i1zV7t5J62TL417/UIS8SrZR87YmKrYpIkK2Z8zGDFt/E9K8m7NXrKybdq96XSHRS8lUd/fq5YUcVWxWRIPCnZwKQX5C7V6/v0sVdK/kSiU5Kvqrj6qth6lSvoxCRGOHzu+QrULB3lVJbt4aMDFi8OJhRiUi4qNREdXTq5HUEIhJD/BlZAOTvxfZC4KahHnQQFBcHMyoRCRclX9X14Yeu5tfZZ3sdiYhEubQ6FclX3l4fY/r0YEUjIuGm5Ku6nnnGbaim5EtEaimhSVP+s9/f2L/HQK9DEREPaM5XdfXr5zZT27zZ60hEJNqlpnL8uXexX+fD9/oQ330Hhx4KX30VxLhEJCyUfFWXiq2KSBBNefXvzPns9b1+fd26LvH65psgBiUiYaHkq7r69HH7eqjel4gEwciv/86jU+/Z69c3bw716qnchEg0UvJVXXXquOI6333ndSQiEgN8ZQkEygr3+vXGuGKrKjchEn004b4mPvnEnWqKiNSSvzSB/FokXwA9e8KLL0JREaSkBCkwEQk5JV81kZXldQQiEiP8NpFAWVGtjnHCCbBmDWzaBE2bBikwEQk5DTvWRG4uDBsG777rdSQiEuV8NokAtauSeuyxMHGiEi+RaKOer5rIyID//heshb/8xetoRCSKPTT0RUrTgjNW+Pvv0KBBUA4lImGgnq+aMAbOPBPeece1diIie6nTEafT9eCTa32csWOhSRPIyQlCUCISFkq+amrkSCgshBde8DoSEYlicyY9zYQXr6v1cXr2hNJS+PTTIAQlImGh5KumOneGI4+Ep592LZ6IyF54beojXLHisVofp18/8Plg2rQgBCUiYaE5X3vjhhvcaWYg4OaBiYjUkD8hlfzEslofJzUV+vdX8iUSTWrV82WMuccYs9AYs8AYM8UY0zxYgUW0E06AMWOUeInIXvMl+ShJgJKyklofa9AgV/957dogBCYiIVfbYceHrLXdrLU9gA+BO4MQU3QoK4OPPoKff/Y6EhGJQv6kNAACxYFaH+u002D8eJ0PikSLWiVf1tqtVe6mA7Z24USR336Dk0+GRx/1OhIRiUL+5HQA8ovza32sdu3goosgM7PWhxKRMKj1hHtjzH3GmNXAucRTz1fjxq7sxL//7YqviojUwJmXPMzio9+nvq9+UI63Zo3r/bLxcwosErX2mHwZY6YZYxbv5DIEwFo72lrbCpgAjNrNcUYYY+YaY+ZmZ2cH7xN4adQo2LoVXn3V60hEJMo0aNeFzocMITkxOSjH+9//4JJL3NwvEYlse0y+rLWDrLVddnKZtMOPTgB2WfbdWjvOWtvbWtu7UaNGtY07Mhx8MBx4IDz5pE43RaRGVs2ZymNjTmP9hhVBOd6gQe5aqx5FIl9tVzu2r3J3CPB97cKJMsZU9n6tWeN1NCISRX78+iOuCUxk+apvgnK8Nm1gv/2UfIlEg9rO+XqgfAhyITAYuDoIMUWXc891Kx5btfI6EhGJIr40tzQxkB+8fYEGDYJPPoHi2u3XLSIhVtvVjn8pH4LsZq09yVobf1VmkpMhKcm1dtu2eR2NiEQJv68uAPmBrXv4yeobNMit/1m0KGiHFJEQ0PZCwZCX59Z6P/CA15GISJTw+11diEAQk6/jjoONG6FXr6AdUkRCQMlXMKSnu9Zu3Di36baIyB74KpKvguD1mPv9ECvrmURimZKvYBk1CrKz4e23vY5ERKJA88OOY+XpX3D2ybcF9bhffAEnnqjygyKRTMlXsAwcCB06uLITIiJ7kOTPoE3nQ/FnZAX1uEVF8J//wGefBfWwIhJESr6CJSEBRo6E2bPhm+AsHReR2GW3bOH+e45m+pTngnrcQw6BtDSVnBCJZEq+gumCC1yL16OH15GISIQzgQB/L5rGlG/fC+px09Lg8MOVfIlEMiVfwVS3rht+NMbrSEQk0vl8+Ishv6T2G2vvaNAgWLwY1q8P+qFFJAiUfAVbaSlcdx089ZTXkYhIJCtPvgLFgaAfevBgN/wYK9voisQaJV/Blpjo5nw99JBLxEREdiYlBV8JBEqDX56mRw/48kvo1i3ohxaRIFDyFQqjRsGqVW7JkYjIzhiDv9SQX1oQsrfIywNrQ3Z4EdlLSr5CYcgQaNlSZSdEZLc+u205E26eE5Jjf/ABZGXBDz+E5PAiUgtKvkIhKQkuvRSmTlXLJyK7VK95O3x1glvnq0LXrm7LWa16FIk8Sr5CZfhwuPBCl4iJiOzES2PO4ZEnzgnJsffZx205O3VqSA4vIrWgzCBUmjSBF1/0OgoRiWAfrJjMD1llXBei4w8aBK+/DiUlOg8UiSTq+Qq1+fNhxgyvoxCRCOQjmQAlITv+oEFuj8evvw7ZW4jIXtC5UKiNGAH5+bBkiYqvish2fCaF/ISckB3/qKPgwQehVauQvYWI7AX1fIXaVVfBd99p1quI/Ik/IYVAQlnIjt+gAdx0k1t8LSKRQ8lXqJ11lpv/9eijXkciIhHGl5BKQQiTL4CtW+G991zNLxGJDEq+Qi01FS6/HCZPhmXLvI5GRCLIvQ9/Q+Cu0M35ApgzB/7yF/jss5C+jYjUgJKvcLjsMmjYEBYt8joSEYkgSak+TEJom+FDD3XngJr5IBI5lHyFQ5MmsHatO/0UESn3+av3MfyWzuQUhG7Svc8Hhx2m5Eskkij5CpeUFLfJ2tq1XkciIhHixx9m8i/fUrYENof0fQYNgoULYcOGkL6NiFSTkq9wuuQSdwpaWup1JCISAfwp6QDkB0LX8wUu+QLN+xKJFEq+wumEE2DlSrfjrYjEPV958hXI2xLS9+nZE5YuhdNPD+nbiEg1KfkKpyFDoHVreOwxryMRkQjgS61IvkLb85WYCAccoDrPIpFCyVc4JSXBlVfCp5/CggVeRyMiHktPr0dGERQX5If8vZYtgwsvhBUrQv5WIrIHSr7C7ZJLwO+HF17wOhIR8dihw+8h9z7LkX3PDvl7JSTASy/BlCkhfysR2QMlX+GWleU22n74Ya8jEZE4su++0KYNTJ3qdSQiouTLC336uNITIhLXfl8wk6HXt+Hj6aHvCTfGrXqcPh0KCkL+diKyG0q+vPLee9C3LxQVeR2JiHikdMsm3qj7C9+vnh+W9zvnHMjJgQkTwvJ2IrILSr684vfD7Nnw9tteRyIiHvGlZwIQKAzPrtcDBsBxx2nVo4jXkrwOIG4NHgwdOsCjj7rTUbWGInHHl14PgPyi8CRfxsDkyWF5KxHZDfV8eSUhAa6+GubOhZkzvY5GJKYZY+4xxiw0xiwwxkwxxjQvf9wYYx43xiwvf75XOONKyqhLcikEikJfaqKqkhLt9SjiJSVfXjr/fKhXT0VXRULvIWttN2ttD+BD4M7yx48D2pdfRgDPhDWq9HTa5ibiS0wN69s+9xwcfTTMmxfWtxWRchp29FJ6uis50ayZ15GIxDRr7dYqd9MBW357CPCytdYCs4wx9Ywxzay168MSWIMGLBtbEpa3quq88+DWW13z89prYX97kbinni+vXXyxmwErIiFljLnPGLMaOJfKnq8WwOoqP7am/LGYlpkJI0bAW2/BL794HY1I/FHyFQnWrYM77oC88Ey6FYlFxphpxpjFO7kMAbDWjrbWtgImAKNqeOwRxpi5xpi52dnZQY37yiv34+6xpwT1mNVx9dVuAr5mPYiEn4YdI8FPP8G990LLlnDppV5HIxKVrLWDqvmjE4DJwN+AtUCrKs+1LH9sx2OPA8YB9O7d2+74fG3MKllJo9/CP/TYqhWceSZ8/jlYqwXXIuGknq9IcOih0KsXPP64awVFJKiMMe2r3B0CfF9++wPg/PJVj32BnLDN9yrnL0sg33pTbPnpp2HWLCVeIuGm5CsSGOPGAJYu1fpvkdB4oHwIciEwGLi6/PHJwE/AcuB54IpwB+azSQQ8Sr4yM13Vm7w8KC72JASRuKTkK1KcdRY0aaIJGCIhYK39i7W2S3m5iZOstWvLH7fW2pHW2n2ttV2ttXPDHZvPJpFvvct8fvzRDUG+9ZZnIYjEHSVfkSI1Fa680p2KloR//oeIeGOflMa0Sqjn2fvvuy80bQr//KdmPYiEiybcR5LRo72OQETC7JGnlnv6/gkJcN11MHw4zJgBRx3laTgicUE9X5Fo1iy37ZCISBicdx40bux6v0Qk9JR8RZqSErft0GmnQZDrCYlI5Hn+byfR/5YmnsaQluZmPfz3v7BihaehiMQFJV+RJikJXn8dNm6EoUM1/0skxq3btJLPfRspLSv1NI4rroCZM90cMBEJLSVfkejAA+GZZ+Djj+H2272ORkRCyJfkA6CgpMDTOOrXh759PQ1BJG4o+YpUF13kqt0/+CB8+qnX0YhIiPjLk6/84nyPI4GyMrjsMrjnHq8jEYltSr4i2WOPuRLUhx3mdSQiEiK+ZJd8BUoCHkfiVj5u3Ahjx2qrWZFQUvIVyVJT4fLLITER1q6F3FyvIxKRIGveeD8O3pKBiZAaWzfcAJs3w7//7XUkIrFLyVc0yMuDPn3g4otVBVEkxhx3zZPMGptLq3qtvQ4FgEMOcXO/HnkESr1dAyASs5R8RYP0dLjmGnjnHXj4Ya+jEZEYd/318NNPMGmS15GIxCYlX9Hihhvg9NPh5ptdGWoRiQkLXh9Lt+t8fLXg/7wO5Q+nngq33go9engdiUhsUvIVLYyB8eOhQwe3Cffq1V5HJCJBUJKXy6LMAn7fvM7rUP6QmAj33w/t2nkdiUhsUvIVTerUgffeg8GDoW5dr6MRkSDw+zMByM/P8TiSP5s5E8aM8ToKkdij5CvadOwIr74KmZlQXOx1NCJSSz6/O5EKFETeauYPP4RbboFvv/U6EpHYouQrWmVnuyVJL77odSQiUgu+ip6vCEy+rr8eGjWC4cO18lEkmJR8RausLKhXz9UBmzfP62hEZC9lNG3FUVuyaFa3udeh/En9+vDoo/D11/DUU15HIxI7jPWgblTv3r3t3Llzw/6+MSc72+0DmZAACxdqHphENGPMPGttb6/jqK14a7+shRNOgM8+g6VLoXVklCMTCatgt19B6fkyxlxvjLHGmIbBOJ5UU6NG8Oab8MsvcNttXkcjIjHIGLfL2c03Q5MmXkcjEhtqnXwZY1oBg4Ffah+O1Fi/fnDVVW7z7YD3e8OJSA1t3EiPq1P52+Oneh3JLrVtC3fc4XY80yYbIrUXjJ6vscBNgP5LeuX++2HuXPD5vI5ERGoqOZlfU4r4NW+D15Hs0aefwsEHu70fRWTv1Sr5MsYMAdZaa7UQ2Ut+vzsl3boVJk/2OhoRqQmfD18xBEoKvI5kj+rWhfnz4cYbvY5EJLrtMfkyxkwzxizeyWUIcBtwZ3XeyBgzwhgz1xgzNzs7u7Zxy87ccQeccgosXux1JCJSXamp+IshvzTypw307AnXXQcvvACffOJ1NCLRa4/Jl7V2kLW2y44X4CdgH+BbY8xKoCUw3xjTdBfHGWet7W2t7d2oUaNgfgapcMcdrvjqX/+qojwi0cIYfGUJBEoLvY6kWu66y207dOmlUBD5nXUiEWmvhx2ttYustY2ttW2ttW2BNUAva+2vQYtOaqZhQ1eUZ/ZstzxJRKLC0Skd6Vu/u9dhVIvfD88+C8uWuc02RKTmkrwOQILsnHNgwgS49VYYMkRFeUSiwD8eW+J1CDVy9NFu8v3hh3sdiUh0ClqF+/IesN+CdTzZS8bAM8/AwIFaEy4iIdO/v2tu1q/XLAeRmtL2QrGoTRuYNMldi0jEu/zSlvS8NcvrMGrsxx+hQwc3DCki1afkK5atWQPDhsFv6pAUiWRFZUVkm8hf7bij/faDvn3dLIc1a7yORiR6KPmKZZs3wxtvuLXhIhKx/CaF/IToG7szxvV6lZTAyJGa6SBSXUq+YlnXru6U9JVX4KOPvI5GRHbBl5BKIAqTL3BlJ+6+Gz74AN57z+toRKKDkq9YN3o0dOwIl10G27Z5HY2I7IQvMZWCREuZLfM6lL1yzTXQqxfMmeN1JCLRQclXrEtNheefh1Wr4B//8DoaEdmJ3u2P4JKSbpSWRWfvV1ISfP45PPig15GIRAfV+YoHhx3mqiEef7zXkYjITpx0zTOc5HUQteT3u+vZs+H339XciOyOer7ixbnnQlaWmxlbXOx1NCKyA1tWho3yGevWwi23wF/+Al9+6XU0IpFLyVc8yc2FPn1gzBivIxGRKt6863QS707kx00/eh1KrRgDb73lNtY48URYvNjriEQik5KveFKnDrRv75Ym3X47ZGd7HZGIACkJyVgDgYJcr0OptUaN4H//c8OQxxzjppuKyPaUfMWbp56Ck06C++93FfCvuQbKonOFlUis8KVmAJC/bbPHkQRH27auuk1+Powd63U0IpFHE+7jTcOG8M478P33bmnSL79AQnkOvnEjNG7sbXwiccifmgEFEMjL8TqUoOnaFWbOdFXwRWR76vmKVx07wosvukQMYMUKaNkSzjoLFizwNjaROONLqwNAft4WjyMJro4dXRmKdevgyiuhqMjriEQig5KveFfR65WZCddf78YKevZ068S/+MLb2ETiRPPOB3NVQXfaNNzX61BC4tNP4ckn4cILNctBBJR8SYWGDV0R1lWr4L774OuvYeBANxQpIiHV4vATeOwfC+h6wJFehxISQ4e65uX11+Haa7UHpIiSL9levXpw220uCZs82c0Bsxaee07bE4mEiC0rI7B1E4UFeV6HEjI33+wSr8cf12YbIkq+ZOf8ftfzBbBwIVxxBRx0ECxZ4m1cIjFo62dT8I9twNNvXu91KCFjDPzzn3DeefDaaxAIeB2RiHeUfMmede8O06bBpk2uSOurr3odkUhM8aXXAyC/MLZ7lxMSYPx4tw+kz+d1NCLeUfIl1TNgAHzzDRx4IAwbBjfd5HVEIjEjOb0uiWUQKIzdYccKyclup7PCQtcL9tlnXkckEn5KvqT6mjeH6dNd4nXYYV5HIxIzjN+Prxjyi/O9DiVs8vJg3jw4+WRXD0wknij5kppJSnLFWU8+2d1/5hn44ANvYxKJdj4fvhIIxFHyVb++24aofn3o3x8efVSrICV+KPmSvVdaCi+/DEOGuKVMJSVeRyQSnerW5YbUARzX8SSvIwmr1q1d79cJJ7iVkNdc43VEIuGh7YVk7yUmwowZcN11MGaMGzt44w03PCki1efzcdM9072OwhNZWTBxotsDsn9/r6MRCQ/1fEntpKXB00/DhAkwfz707g25uV5HJRJ1Nq9dQfb6FV6H4Qlj3Dlc797u/o03utKCGoaUWKXkS4LjnHNcVfy//x3quH3q1HKKVN9Jf+/A2U8d6XUYnisuhsWL4bLL3GpI1XaWWKTkS4LngANg+HB3e8oUN4awcqWnIYlEC39ZIgFb7HUYnktOhv/8B+69181iOOggl4yJxBIlXxIaeXmuMn737q6ctYjsls8mkm+LvA4jIiQkwOjRrrbz5s1w1FGuSRGJFUq+JDROPRW+/Ra6doVzz3WFWbdu9ToqkYjlJ5kA6vmqasAAWLDAbaqRnu5mMhQWeh2V50TLzwAAGLFJREFUSO0p+ZLQadsWPvkE7rrL9X69+67HAYlELh/J5BuVa9lR06YweLC7PX68G4b89ltvYxKpLSVfElpJSfC3v7nW8sIL3WMLF6ommMgOzupzEaPbDvM6jIjWqhWsXw89e7oO9RXxuThUYoCSLwmPLl3cevKNG93WRAMGwKpVXkclEjGOufQhLhs+zuswItrgwbBsmavpPHEidOzoSgyKRBslXxJejRu7umDffusm47/xhtcRiUSEzb/8wHffTMGqRMtuZWXBP/7her0uvdSd14GbUvr7797GJlJdSr4k/M47z82iPeAAGDoULrhAw5AS95578Ew6fXAMhaWaUV4dzZrBk0/C8ce7+2PGQLt2cM89qvMskU/Jl3ijXTv47DO44w5ITXVzw8DtFykSh3xJaQDkx9Hm2sE0dCgMHAh33gn77us26i4o8DoqkZ1T8iXeSU6Gu+92+4iA256ofXu3WbeSMIkz/iQ/AIHigMeRRKfOneG992D2bOjWzW3UffnlXkclsnNKvsR7xrjr0lKoX98NQ3bvDpMmaYsiiRu+ZB+gnq/a6tPHFWedNs3tEQmwZInb+Wz1am9jE6mg5Esix0EHuf0h337bbfB2yilwzDFKwCQu+FPSAQgo+QqKgQOhUyd3e8YMV26wbVs46ST4v//TNFPxlpIviSzGwOmnu1PV5593LaUxLgFbssTr6ERCptegYYzLHEbzjGZehxJzRo1yqyNvuQXmzoWTT3arJMvKvI5M4pWSL4lMSUnw17/ClVe6+5MmudbyrLNcoR+RGNO2/8kMv+ZlGmY09jqUmNSuHdx3H/zyi6sRNmqU20PSWnd70iT1hkn4KPmS6DBgANx+O3z4oRtLOP98+PJLDUlKzMjfsIa5U19i05b1XocS05KT3YyGUaPc/Q0bXDJ2yinQurVrZn74QU2LhJaSL4kOmZmugM9PP8HIkfD++26z7ooWslgbEkt0W/Hhyxz01YVMn/+O16HElaZN3WYbkyZBr16ugGvHjjB5snt+wwb4+WdvY5TYo+RLokuTJvDYY7BunTtdTUiAwkI3pjBsGHz+uU5ZJSr50uoAEAioQmi4JSW5eWAffggrV8Kzz8Khh7rnxo93zUvbtnDRRa4SjlZNSm0p+ZLolJHhylEA5OW5lvODD6B/fzcsOXYsbNrkbYwiNeBPrwdAfmCrx5HEt1at3LZF9dzXwVlnwRNPwIEHuibmggtcOcKKAq7ffuvOBUVqQsmXRL/69eGpp1wLOH68azWvuw6WLnXP5+WpN0wins+fCUCgYJvHkUhV7dq5+WHvvgvZ2W5ntJdfhjS3IQGXXQYtWrik7bTT4IEH4KuvvI1ZIp+SL4kd6eluXGDmTFeWomLc4Kab3D6S6g2TCObPKO/5KlTyFakSElyH+5lnVj721FOuaenfHxYtgltvhQcfrHz+xhvhmWdg3jwoKgp/zBKZlHxJbOrUqbJy/hFHQIMGrjesRQu48EKYM8fT8MQbxpjrjTHWGNOw/L4xxjxujFlujFlojOnlVWwp+3fitaajOKXvhV6FIHuhVy+45hqYMAF+/BF++83tKwmu0/3ll+GKK6B3b6hbF/r1c3WkwW3qsXmzd7GLd5K8DkAk5M48010WLnT7SL7yitvMu08fNxyZl+fmkElMM8a0AgYDv1R5+DigffnlYOCZ8uuwMw0bMvTSJ7x4awmiBg3cBVxn/K+/utWUX3/tzvnmzHFNDriSFp07uxWXnTu7c8bOneG441zZC4ldSr4kfnTr5sYIHnwQ8su3cJk1CwYPhnPPdZM3evTwNkYJpbHATcCkKo8NAV621lpgljGmnjGmmbU2/MW2ior48r/PUW+fA+jcbVDY315Cwxi3UrJtWzjjjO2fy8qChx5ysySWLHFTVvPy3PZHrVu7xdt33eWSsrZt3byy1q1dU+b3h/+zSPAo+ZL4k5FR2dNVv77bzuill1yv2MEHuyRs6FDXOyYxwRgzBFhrrf3WVAxHOy2AqoUD1pQ/Fv7kKzeXoZ9excClfXhRyVdcaNYMbrih8n5ZmStj0bChux8IQG6ua55yq1Qg+fZbl4C9/rqbT1aRlFVcDxwIPl94P4vUjJIviW8dOsCLL8Ijj7jJGc8+C9df79aXA7z1lrs++GDXqm3/h1siiDFmGtB0J0+NBm7DDTnu7bFHACMAWodqPMjnw18M+SWB0BxfIl5CArRpU3l/8GB3sRZyctzWSKtXw377uecTE12T9NVXrqmq2B7p999d8jV6NIwbB40bb38ZO9bVNlu82B23cWNXQrFOHTVx4aLkSwRc///VV8NVV7kqixWnjQ8+CPPnu9tNmrh5YieeCCNGeBaq7Jy1dqfdRcaYrsA+QEWvV0tgvjGmD7AWaFXlx1uWP7bjsccB4wB69+4dmrolaWn4i2FbqZIv2Z4xroJOvXqux6tCxXRWcJP3N2xwCVpWlnusTx+3wHvjRndZsAC2boXHH3fPjxnjpsBWSEtzid2iRe7+c8+56v5NmlQmaM2bu2FQqR0lXyJVGQP77FN5f+ZM1xLNnu0uc+a4PSVHjHCno4cfDvvu6yowtm7tVlO2a1c541Y8Z61dBPyxW7UxZiXQ21r7mzHmA2CUMeYN3ET7HE/mewEkJNB+SwJvNVvO0HeH8tppr2HUDSHVlJjoEqPmzSsfGzLEXXblzjvddNcNG1wNsw0btn/+44/dTm5Vd2/r1MnNTwPXK/fddy4pzMpyl5493Tw1cMOixcWViWNWVmUSF++UfInsTkqKS6wOPNCtFwd3igluZmz9+vDRR27IssLo0XDvve6U85hjXELWvHnl9eGHu9NLa9XH773JwPHAciAfuMjLYF6YUZeurTtQXH//PxKvDds20CRDf63CoqDALU2sW9dNyIpx++1XOYS5M2+95ZqpLVtcz9mGDW5eWoVBg1yztmWLu6xa5YYuK4we/ed9MU880S0oAOja1f3KKxKzevXcMUf0/x6eeIJ/pY7E16MDmfUTycx0W/w2b145Jy6aKfkSqanERHedkeH2G7HWtUpr17oq++3auecDAdcD9tNPbtlSRYHXZ591Ld7Cha4G2Y6zZU8/Hfbf350yWusSQAkaa23bKrctMNK7aLaX8cqb3N6ihas3AEz7aRonvnYiIw8aya2H30pDfwz81fFSaSmsWeP+T/78Mxx1lFtGOHWqq/9XsU9QQgKcdJIr2NW2rYcBV1NxsRtvXLHCXQoK4Nprg3JoYyp7tTp02P65m27a/WvnznV1zDZvrkzQqiZORx/tSnFs2VDI5mWbWF3ko23benB+W8omvM6InCewO5Qjveoqt71vQYHrQatIyurWdStAL7gAzjvPLVAYPdqV+/D7Ky+HHQZdO5e5CXIetq1KvkRqyxhXqKdpU9dDVqFFC9crVqGgwDXuFZvG1akD559fOYt2zhxXobFHD5d8TZni/gA0beoSs3btXNI2fLhL0oqL3axZ9Z7FjsHbrwno0KAD53Y9l0dnP8rz85/nxkNu5Np+15KR4mFduqIi95ctN9dNINp/fzdZaOlSN0xfsZ2XMe5y4YXu3/q8ea7YVUJC5XPGuL+Uqak17gneFNhEXlEegZIA+cX5BIoDZKZl0qlRJygr49UpD5GbWEYgIxXWryftXy/S+YctHPGT67n+T3tILr6R1GNOIC3td1JPPJCmzc+habtu2KVL2PLea6RlpJJqy0hYvMT9f65fP0S/1GrIza1MroxxexmB60mfObOyRx5gZPn5hLXw5JPuhM6Dnrz69XfzK9u6lUe6T4TFE+CTj12X2hlnwJi3gDTMurWse+Mjct6dRs70eeQUpJBz5yO0G9IVtm2jtMzHRRclkpPjFg1s3er+6VXsubl1q5vPlp9vKSqq/Hc19oa1dH2+s6vxMXx4yH8Hu2KsB3ve9e7d286dOzfs7ysS8fLzXUKVkgLffw9vvumSs19+cWfrq1bBN9+4/vqKlZn77rv95bzz3B+7sjL3hy5CGGPmWWt7ex1HbYW0/frsM/dHtH//yiQF+C77O26fcTvvffceXRp3YeFlC4M/Hyw729W9W7u28rJunev96djR/SX761//vEfO4sXQuTMljz5C/i3XU7fQPWwBA+7fbqtWcM89bpLRjjZtct0qt93mxrl69IAePfi6vZ9lTZJZmZDDyi2rWJmzko4NOvLE8a4QbYtHWrAud/sdrc8o7chbXzaHuXOpd8VWctK2f6vhpT0Y1+oKbNu2JHz158Wv1/a9lkeOeYS8ojwy/lGZ4CaXGdKKLbflH8gtw57jtwPaMPDlgaQlpW13ubjHxQzpOITsvGzu+/y+Pz0/qN0gujTuwpaCLXy+6nPSU9JJT04nPdlPel4RTX8rwLd2I2zbBsOGlQc9HCZNct9Phc6d3e8d3O+1qMidnFW0Ac2auX8/8+e7E8LERDjhBPf9HXeca2NqoaSshK2BLeQENpNTkkdOQQ7FZcUMaufWvLy26DUW/LqAnIIccgrdpXF6Y1468QVISuLRWY+y6tWn8H+3nPSMLPzde9PysOM5ffA1AMxZO4dAcaDy33hBAZlzF9P9rKsgKYk5N55DYPr/4Igj4agB0LkzDdIb0aVxFygtZcEH4yhdsojExUtJXLwE++sW0i65nrrXPkB66Va23jeSzDOHkXFk9RdAB7v9UvIlEk2Ki12jmpjo1pe/8447E16+3CVnBQWuj79ePbj5ZnjiCTf0Wb9+Zent1193je8nn7iVnRWPN20KLVuGrCteyVc1HHro9rsyJyfDHXe4y8aNzB50AOvrwCnr6lKSnMjEtgWcdvbfSbz4Ekp+WUnhReeTlpRGYmoaW9Jgrb+UglNPpKBnNwp+XU3BO28woKAZ/nXZLMr5ka/LVlN8/nkUH7A/xYsWUPziC4yaA/7SBKYcWI9pHZMpHHgkeVkZ5G1YzbbVK3g/5QIS62Zyd9kMXsj/gm2JpeQV51NYWkhaYiqBy9eCMVwy7Sre+HEidVLrkJGSQZ2kdJqlNWTysa9AWRnjvnuV77Ysx5fViI352az8YTaZ6zfz7v/5YPlyDhoOc1u4X0OT9Ca0La3DUWkHcP+R98DGjbw86zmK6vjxHXUM/oRUfGedS8stZXRp3gP69GFVr3akHtIf3z77A1BQUkBKYgpZviystcxbP4/CkkIKSwv/uN6n3j50b9qdwpJCnp37LAUlBe6y7hcKvvmawR8t47jFhfx2aE+Gn5FGQcNMCkoKCBQHKCwt5Lq+1zGs+zC+/+17+v6rLwUlBRSWFv7xdf6r3bVcUtKV2b/OpW/R03/6+l9/B85eDDM6p3PiOdYlZoES6hQZmqY24N42F9GnyzH80iiF2Vu/o1mdZjTLaEazOs3wJ++i6uqPP8L48QReHk/auo2Y5s1Z+u6zzPfnsDFvI9l52fyW/xt5xXm8cuorJCYk8sjMR3hzyZsEigMECnIpCGyD4iJWLzoaLriAYSVv8erCV7d7m4YFiWR/2gfuuovTNj/L5GX/IbM0icwEH5mJ6ey3NZnX/7UZ5s/npK9G8elPM8grCVCGm0R2UPODmDPcbfvW87meLPh1wXbHH9B2ANMvmA5A+weas7xw+3UxJyd3YdJti6C0lCa3JrMxffvc5pzWJzDhog8BSL8/nQcHPcioPqN2/jvbiWC3Xxp2FIkmycmVtw85xF0qlJXB+vWVw5pHHOF6UTZtcoV/fv/dJWkVZ70vvACvbt+AkpnpJmaAm1ixcuX2c9LatHFJmoTGI4/A9OluPkpxsbvu1889l5LCwYec4R7fr4T3U1dwZosvSV1zOSV3X0qpLYX+8M0XXeixJpnXW/7KFZ3Xw4LJUPF3LB1+fDOD/fwt+e/BJdy8z2ZY+QSsLH/+aDj/xfn49+nKV1/cyxNfPkjK+v+S8XsG6cnpZLSoS+HF1+NP9rPPt1kM+DmTjJTy51IySE9Jx9avjzGGYzsPIateU3ILc9lWvI3cwlxSk1L/WI73xddLeX/5++QV59E4vTFt67el/QGHwSPPQG4uz3/5Lmmbc2lz+l/xJfvgoINg7v8Bbrb2+eCGqa4518X+1gGu1yfNdXdVKZcFQCaZf9w2xtC7+a7/jqYmpXJ136u3f/Ac4PYceOUVGj79NBPrXgnnXuTGvObOdf+/ZqyDV2+k49q1bHluNdSpQ9no2yga8w8KkiC1ZCyUQOcUmLN4BnnJkDflQ/JWfE9eg7ocfPsR0P4gmtct4rIVb5NXnEdecR5bC7eyYdsGEgYdDc178dnCVxk2cdj2ny81kxkXzKBns558svITHvrqIbLzssnOzya7TjZ5I/L4tfO/aTJxCm9sm8U9/7sfgCQSaZDekDqpdSj6fgm+xFRSE1PJSsyg+ecL8OUVkVYC/mJg2bewaRNn9zub3untyZy1gLp5JWRuKyErpxDSEyA5mbfPeJvETz6FY4+F4nzgdzfh6pRToKiI/xvqvkNrLUWlReQX51NSVvLHZ3nh5BfYUrBlu8+XlZb1x+2Xz32XgpICN1Iw8yv45BMaFpefNCYm8upRTxBonEWpz0epLaW0rJRWmZUVZZ487kn6tOizy+8/HNTzJRKvcnPdUEZFYrZ+vVskULGq87zz3Drzio3oYPt15jWknq/gKrNlvPfde8xcPXO7oa1h3YfRNKMpyzctZ/76+X8a+urWpBtpSWlsKdhCTkEOyYnJJCck/3HtT/ZHZomLkhK3GeLChdCokdupuuJEI9ysdSc7iYluWLbq5PbUVDc/bPp0d7Ly+edurlvFiucWLdywYC1K0G8r2sbPm39m/bb1rMtdx/rc9azftp7Rh4+mSUYTxs0bx7Nzn6VReiMa+csv6Y24vPflZPmy+HXbr+QW5tLojAvInDETU6+e+/1u2wbnnON2CbcWrrzSzenr2RO6d3ez2mv6eyoocCd0mZlRvSdSRA07GmPuAoYDFYPRt1lrJ+/pdZHSeInIHljrhjFXr3Zzd8AtAtgLSr4kJq1b5+ZfNWvmEqz69aNnEUxZGUyb5qYiZGS4JKtvX1VR3YlIHHYca639ZxCOIyKRxpjKJUvdu3sdjUjk2bGyaTRJSKjcw0jCKnKWQomIiIjEgWAkX6OMMQuNMeONMVl7/nERERGR+LXH5MsYM80Ys3gnlyHAM8C+QA9gPfDwbo4zwhgz1xgzN7tqvRIRERGROLLHOV/W2kHVOZAx5nngw90cZxwwDtyE1eoGKCIiIhJLajXsaIypul/BqcDi2oUjIiIiEttqu9pxjDGmB24niZXApbWOSERERCSG1Sr5stYO2/NPiYiIiEgFlZoQERERCSMlXyIiIiJhpORLREREJIyUfImIiIiEkZIvERERkTBS8iUiIiISRkq+RERERMJIyZeIiIhIGBlrw7/NojEmG1hVzR9vCPwWwnAikT5zfIi3z9zGWtvI6yBqq4btF8Tf9wzx95nj7fNC/H3moLZfniRfNWGMmWut7e11HOGkzxwf4vEzx6N4/J7j7TPH2+eF+PzMwaRhRxEREZEwUvIlIiIiEkbRkHyN8zoAD+gzx4d4/MzxKB6/53j7zPH2eSE+P3PQRPycLxEREZFYEg09XyIiIiIxI6KTL2PMscaYH4wxy40xt3gdTzgYY1YaYxYZYxYYY+Z6HU8oGGPGG2M2GmMWV3msvjFmqjHmx/LrLC9jDKZdfN67jDFry7/nBcaY472MUYJP7Zfar1ihNiz4Ijb5MsYkAk8BxwGdgKHGmE7eRhU2A6y1PWJ4Ge+/gWN3eOwW4GNrbXvg4/L7seLf/PnzAowt/557WGsnhzkmCSG1X2q/wh1UiP0btWFBFbHJF9AHWG6t/claWwS8AQzxOCYJAmvtZ8CmHR4eArxUfvsl4JSwBhVCu/i8EtvUfsWoeGu/QG1YKERy8tUCWF3l/pryx2KdBaYYY+YZY0Z4HUwYNbHWri+//SvQxMtgwmSUMWZheZd+TA1TiNovtV9xQW3YXork5CteHWat7YUbrhhpjOnvdUDhZt0S3FhfhvsMsC/QA1gPPOxtOCJBofYrPtovUBtWK5GcfK0FWlW537L8sZhmrV1bfr0RmIgbvogHG4wxzQDKrzd6HE9IWWs3WGtLrbVlwPPEz/ccL9R+qf2KaWrDaieSk6+vgfbGmH2MMSnA2cAHHscUUsaYdGNMnYrbwGBg8e5fFTM+AC4ov30BMMnDWEKuoqEudyrx8z3HC7Vfar9imtqw2knyOoBdsdaWGGNGAf8DEoHx1tolHocVak2AicYYcN/Na9baj7wNKfiMMa8DRwINjTFrgL8BDwBvGWMuAVYBZ3oXYXDt4vMeaYzpgRueWAlc6lmAEnRqv9R+eRdh8KkNCz5VuBcREREJo0gedhQRERGJOUq+RERERMJIyZeIiIhIGCn5EhEREQkjJV8iIiIiYaTkS0RERCSMlHyJiIiIhJGSLxEREZEw+n/Xj1rbce2IdAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x1080 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 27s, sys: 4.38 s, total: 11min 31s\n",
      "Wall time: 11min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if __name__ == '__main__':\n",
    "    # set the gamma\n",
    "    GAMMA = 1.0\n",
    "    # make the environment\n",
    "    env = gym.make('MountainCar-v0') \n",
    "    # set up the bins, breaking pos and vel in 8 separated bins for each\n",
    "    posBins = np.linspace(-1.2, 0.5, 8)\n",
    "    velBins = np.linspace(-0.07, 0.07, 8)\n",
    "    \n",
    "    # list of tuples with possible combinations of buckets for an observation\n",
    "    stateSpace = []\n",
    "    for i in range(1,9):\n",
    "        for j in range(1,9):\n",
    "            stateSpace.append((i,j))\n",
    "    # number of games\n",
    "    numEpisodes = 20000\n",
    "    # keep track of the value function estimates at the near exit point at the left side of the track\n",
    "    # to plot this we use a list of x values, wchich is just zero to the number of games divided by 1000 - 1\n",
    "    # the dimention of 3 will help plot for three different alpha value \n",
    "    nearExit = np.zeros((3, int(numEpisodes/1000)))\n",
    "    leftSide = np.zeros((3, int(numEpisodes/1000)))\n",
    "    x = [i for i in range(nearExit.shape[1])]\n",
    "    # loop through 3 learning rates\n",
    "    # hyperparametar tunning: part of the art of Rl!!!\n",
    "    for k, LR in enumerate([0.1, 0.01, 0.001]):\n",
    "        print(\"For alpha: {}\".format(LR))\n",
    "        dt = 1.0\n",
    "        # initialize a new model for each learning rate\n",
    "        model = Model(LR, stateSpace)        \n",
    "        for i in range(numEpisodes):\n",
    "            \n",
    "            # update the nearExit and leftSide arrays each 1000 games\n",
    "            if i % 1000 == 0:\n",
    "                \n",
    "                print(\"episode: {}\".format(i))\n",
    "                #print(\"episode memory: {}\".format(memory))\n",
    "                #print(\"statesReturns: {}\".format(statesReturns))\n",
    "                \n",
    "                idx = i // 1000\n",
    "                #print('posBins', posBins)\n",
    "                #print('velBins', velBins)\n",
    "                state = aggregateState(posBins, velBins, (0.43, 0.054))\n",
    "                #print(\"state near exit: {}\".format(state))\n",
    "                nearExit[k][idx] = model.calculateV(state)\n",
    "                #print(\"nearExit[k][idx]: {}\".format(nearExit[k][idx]))\n",
    "                state = aggregateState(posBins, velBins, (-1.1, 0.001))\n",
    "                #print(\"state left: {}\".format(state))\n",
    "                leftSide[k][idx] = model.calculateV(state) \n",
    "                #print(\"leftSide[k][idx]: {}\".format(leftSide[k][idx]))\n",
    "                # increment the divisor of the learning rate\n",
    "                # just a small 0.1 increment every 1000 games gives us a fair convergence\n",
    "                dt += 0.1\n",
    "            # reset the environment, done flag and memory at the top of each episode\n",
    "            observation = env.reset()\n",
    "            done = False\n",
    "            # memory of the rewards to the terminal State\n",
    "            memory = [] \n",
    "            # play the episode according to the policy\n",
    "            # append a terminal state at the end of the episode\n",
    "            while not done:\n",
    "                state = aggregateState(posBins, velBins, observation)\n",
    "                action = policy(state[1])\n",
    "                observation_, reward, done, _ = env.step(action)           \n",
    "                memory.append((state, action, reward))\n",
    "                #print(\"memory: {}\".format(memory))\n",
    "                observation = observation_ \n",
    "            state = aggregateState(posBins, velBins, observation)\n",
    "            memory.append((state, action, reward))\n",
    "            \n",
    "            # do the calculations of the returns at each time step by iterating backwards\n",
    "            # over the memory, skipping the terminal state\n",
    "            G = 0\n",
    "            last = True\n",
    "            statesReturns = [] \n",
    "            # use the memory vector to calulate the return function (sum of rewards from initial state to the end)\n",
    "            for state, action, reward in reversed(memory):\n",
    "                if last:\n",
    "                    last = False\n",
    "                else:\n",
    "                    statesReturns.append((state, G))\n",
    "                G = GAMMA*G + reward\n",
    "            # reverse this list of states and return to put it into the chronological order, and\n",
    "            # keep track of the returns that follow the agent's first visit to that state\n",
    "            statesReturns.reverse()\n",
    "            statesVisited = []\n",
    "            for state, G in statesReturns:  \n",
    "                # updates the model weights if it is the firt visit to that state\n",
    "                if state not in statesVisited:\n",
    "                    model.updateWeights(G, state, dt)\n",
    "                    statesVisited.append(state)\n",
    "    # when we reach the finish of the game, plotthe nearExit and leftSide arrays for each leraning rate\n",
    "    plt.figure(figsize=(10, 15))\n",
    "    plt.subplot(221)\n",
    "    plt.plot(x, nearExit[0], 'r--')\n",
    "    plt.plot(x, nearExit[1], 'g--')\n",
    "    plt.plot(x, nearExit[2], 'b--')\n",
    "    plt.title('Estimated State Value - near exit, moving right')\n",
    "    plt.subplot(222)    \n",
    "    plt.plot(x, leftSide[0], 'r--')\n",
    "    plt.plot(x, leftSide[1], 'g--')\n",
    "    plt.plot(x, leftSide[2], 'b--')\n",
    "    plt.title('Estimated State Value - left side, moving right')\n",
    "    plt.legend(('alpha = 0.1', 'alpha = 0.01', 'alpha = 0.001'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "#### State nearest to the exit and moving right\n",
    "The alpha of 0.001 produces the most reasonable estimate.\n",
    "It is between -1 and -2 and the true values is two moves to the exit.\n",
    "The other two alphas both converge on the wrong answers on either side of it.\n",
    "### State in Left side , moving right\n",
    "All three alphas values converges to the answer -40, which is actually really close to the value of 39 steps required to reach the exit, starting from the left side of the small positive velocity.\n",
    "Note the difference in the slope between the three different values of alpha:\n",
    "For 0.1 and 0.01 converge almost instantly to the correct answer, while alpha 0.001 takes logner to get there.\n",
    "## This highliths the importance of hyper parametar tunning in RL!!!\n",
    "#### Rule of thumb\n",
    "Start with some value and run up and down by 1 order of magnitude (in powers of 10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"lev1\">\n",
    "    <a href=\"#Lecture-3-Supporting-Notebook\"><span class=\"toc-item-num\"></span>\n",
    "        TOP\n",
    "    </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MLU Logo](https://drive.corp.amazon.com/view/bwernes@/MLU_Logo.png?download=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Tiles for Multiple Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_tiling' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-692d807fe42f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m#offsets= [[0,0],[0.5,1.5],[1.,3.],[1.5,4.5],[2.,6.],[2.5,7.5],[3.,9.],[3.5,10.5]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mtilings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_tilings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_ranges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_tilings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtilings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# # of tilings X features X bins\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-692d807fe42f>\u001b[0m in \u001b[0;36mcreate_tilings\u001b[0;34m(feature_ranges, number_tilings, bins, offsets)\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mfeat_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_ranges\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeat_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0;31m# tiling for 1 feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                 \u001b[0mfeat_tiling\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_tiling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtiling_bin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeat_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtiling_offset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeat_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m                 \u001b[0mtiling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat_tiling\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mtilings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtiling\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_tiling' is not defined"
     ]
    }
   ],
   "source": [
    "def create_tilings(feature_ranges, number_tilings, bins, offsets):\n",
    "        \"\"\"\n",
    "        feature_ranges: range of each feature; example: x: [-1, 1], y: [2, 5] -> [[-1, 1], [2, 5]]\n",
    "        number_tilings: number of tilings; example: 3 tilings\n",
    "        bins: bin size for each tiling and dimension; example: [[10, 10], [10, 10], [10, 10]]: 3 tilings * [x_bin, y_bin]\n",
    "        offsets: offset for each tiling and dimension; example: [[0, 0], [0.2, 1], [0.4, 1.5]]: 3 tilings * [x_offset, y_offset]\n",
    "        \"\"\"\n",
    "        tilings = []\n",
    "        # for each tiling\n",
    "        for tile_i in range(number_tilings):\n",
    "            tiling_bin = bins[tile_i]\n",
    "            tiling_offset = offsets[tile_i]\n",
    "\n",
    "            tiling = []\n",
    "            # for each feature dimension\n",
    "            for feat_i in range(len(feature_ranges)):\n",
    "                feat_range = feature_ranges[feat_i]\n",
    "                # tiling for 1 feature\n",
    "                feat_tiling = create_tiling(feat_range, tiling_bin[feat_i], tiling_offset[feat_i])\n",
    "                tiling.append(feat_tiling)\n",
    "            tilings.append(tiling)\n",
    "        return np.array(tilings)\n",
    "    \n",
    "feature_ranges = [[-1, 1], [2, 5]]  # 2 features\n",
    "number_tilings = 3\n",
    "bins = [[10, 10], [10, 10], [10, 10]]  # each tiling has a 10*10 grid\n",
    "offsets = [[0, 0], [0.2, 1], [0.4, 1.5]]\n",
    "#feature_range=[[-1.2, 0.6],[-0.07, 0.07]]\n",
    "#number_tilings= 8\n",
    "#bins= [[8,8],[8,8],[8,8],[8,8],[8,8],[8,8],[8,8],[8,8]]\n",
    "#offsets= [[0,0],[0.5,1.5],[1.,3.],[1.5,4.5],[2.,6.],[2.5,7.5],[3.,9.],[3.5,10.5]]\n",
    "\n",
    "tilings = create_tilings(feature_ranges, number_tilings, bins, offsets)\n",
    "\n",
    "print(tilings.shape)  # # of tilings X features X bins\n",
    "\n",
    "# (3, 2, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tile_coding(feature, tilings):\n",
    "        \"\"\"\n",
    "        feature: sample feature with multiple dimensions that need to be encoded; example: [0.1, 2.5], [-0.3, 2.0]\n",
    "        tilings: tilings with a few layers\n",
    "        return: the encoding for the feature on each layer\n",
    "        \"\"\"\n",
    "        num_dims = len(feature)\n",
    "        feat_codings = []\n",
    "        for tiling in tilings:\n",
    "            feat_coding = []\n",
    "            for i in range(num_dims):\n",
    "                feat_i = feature[i]\n",
    "                tiling_i = tiling[i]  # tiling on that dimension\n",
    "                coding_i = np.digitize(feat_i, tiling_i)\n",
    "                feat_coding.append(coding_i)\n",
    "            feat_codings.append(feat_coding)\n",
    "        return np.array(feat_codings)\n",
    "        \n",
    "feature = [0.1, 4.0]\n",
    "\n",
    "coding = get_tile_coding(feature, tilings)\n",
    "coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"lev1\">\n",
    "    <a href=\"#Lecture-3-Supporting-Notebook\"><span class=\"toc-item-num\"></span>\n",
    "        TOP\n",
    "    </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MLU Logo](https://drive.corp.amazon.com/view/bwernes@/MLU_Logo.png?download=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TD(0) Approximator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the number of layers and bins\n",
    "def getBins(nBins=8, nLayers=8):\n",
    "    # construct the asymmetric bins\n",
    "    posTileWidth = (0.5 + 1.2)/nBins*0.5\n",
    "    velTileWidth = (0.07 + 0.07)/nBins*0.5\n",
    "    posBins = np.zeros((nLayers,nBins))\n",
    "    velBins = np.zeros((nLayers,nBins))\n",
    "    for i in range(nLayers):\n",
    "        posBins[i] = np.linspace(-1.2+i*posTileWidth, 0.5+i*posTileWidth/2, nBins)\n",
    "        velBins[i] = np.linspace(-0.07+3*i*velTileWidth, 0.07+3*i*posTileWidth/2, nBins)    \n",
    "    return posBins, velBins    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the number of layers and bins\n",
    "def tileState(posBins, velBins,  obs, nTiles=8, nLayers=8):\n",
    "    position, velocity = obs\n",
    "    # 8 tilings of 8x8 grid   \n",
    "    tiledState = np.zeros(nTiles*nTiles*nTiles)\n",
    "    for row in range(nLayers):\n",
    "        if position > posBins[row][0] and position < posBins[row][nTiles-1]:\n",
    "            if velocity > velBins[row][0] and velocity < velBins[row][nTiles-1]:\n",
    "                x = np.digitize(position, posBins[row])\n",
    "                y = np.digitize(velocity, velBins[row])                \n",
    "                idx = (x+1)*(y+1)+row*nTiles**2-1\n",
    "                tiledState[idx] = 1.0\n",
    "            else:\n",
    "                break\n",
    "        else:\n",
    "            break            \n",
    "    return tiledState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    # get this inputs and initialize a empty array of weights with the size of \n",
    "    # the number of states\n",
    "    def __init__(self, alpha, gamma, nStates):\n",
    "        self.ALPHA = alpha\n",
    "        self.GAMMA = gamma\n",
    "        self.weights = np.zeros(nStates)\n",
    "    # the value of a particular state is a vector dot product of weigths\n",
    "    # in the binary representation of the states\n",
    "    def calculateV(self, state):     \n",
    "        v = self.weights.dot(state)\n",
    "        return v\n",
    "    # to update the weights, we need the value of the current state at time t\n",
    "    # and the state at time t+1\n",
    "    # we update the weights according to the update rule.\n",
    "    # the parameter t that dictates how much I decrease alpha ovet time.\n",
    "    # It starts one and increases as we play more games.\n",
    "    # Note that this is multiplying our array of weights by a binary representation of \n",
    "    # of the state, so we only update the weights for the state we are interested in\n",
    "    def updateWeights(self, R, state, state_, t):        \n",
    "        value = self.calculateV(state) \n",
    "        value_ = self.calculateV(state_)\n",
    "        self.weights += self.ALPHA/t*(R + self.GAMMA*value_ - value)*state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this simple policy just takes the velocity as input.\n",
    "# It pushes in the direction of the movement\n",
    "def policy(velocity):\n",
    "    # 0 - backward, 1 - none, 2 - forward\n",
    "    if velocity < 0:\n",
    "        return 0\n",
    "    elif velocity >= 0:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "if __name__ == '__main__':\n",
    "    # set gamma to 1.0, make the environment\n",
    "    GAMMA = 1.0\n",
    "    env = gym.make('MountainCar-v0')\n",
    "    # generate the bins, set the number of episodes\n",
    "    posBins, velBins = getBins()\n",
    "    numEpisodes = 20000\n",
    "    # initialize the arrays to keep track of the updates to the value function\n",
    "    # for our states of interest.\n",
    "    nearExit = np.zeros((3, int(numEpisodes/1000)))\n",
    "    leftSide = np.zeros((3, int(numEpisodes/1000)))\n",
    "    x = [i for i in range(nearExit.shape[1])]\n",
    "    # iterate over an enumerated list of learning rates\n",
    "    for k, ALPHA in enumerate([1e-1, 1e-2, 1e-3]):\n",
    "        # for each learning rate, initialize a new model with 8 cube states.\n",
    "        model = Model(ALPHA, GAMMA, 8*8*8)\n",
    "        # The dt is used to decrease the learning rate over time\n",
    "        # so it gets reset for each learning rate\n",
    "        dt = 1.0\n",
    "        # every 1000 games calculate the value of the nearExit and leftSide states,\n",
    "        # and printout a placeholder to the terminal\n",
    "        for i in range(numEpisodes):\n",
    "            sys.stdout.flush()\n",
    "            if i % 1000 == 0:\n",
    "                print('alpha', ALPHA, 'start episode', i)\n",
    "                idx = i // 1000\n",
    "                tiledState = tileState(posBins, velBins, (0.43, 0.054))\n",
    "                nearExit[k][idx] = model.calculateV(tiledState)        \n",
    "                tiledState = tileState(posBins, velBins, (-1.1, 0.001))\n",
    "                leftSide[k][idx] = model.calculateV(tiledState)\n",
    "            # increment dt by 10, so alpha gradually decreases over time\n",
    "            if i % 100 == 0:\n",
    "                dt += 10\n",
    "            # at the top of each episode, reset the environment and done flag\n",
    "            observation = env.reset()\n",
    "            done = False \n",
    "            # play the game according to the policy and call the\n",
    "            # update model function at each time step\n",
    "            while not done:\n",
    "                state = tileState(posBins, velBins, observation)\n",
    "                #print(\"state\", state)\n",
    "                action = policy(observation[1])\n",
    "                observation_, reward, done, _ = env.step(action)\n",
    "                #print(\"reward\", reward)\n",
    "                #total_reward.append(reward) #CASS\n",
    "                state_ = tileState(posBins, velBins, observation_)\n",
    "                #print(\"state_\", state_)\n",
    "                model.updateWeights(reward, state, state_, dt)\n",
    "                observation = observation_ \n",
    "    \n",
    "    # when finished, make two subplots the two state of interest side by side\n",
    "    plt.figure(figsize=(10, 15))\n",
    "    plt.subplot(221)\n",
    "    plt.plot(x, nearExit[0], 'r--')\n",
    "    plt.plot(x, nearExit[1], 'g--')\n",
    "    plt.plot(x, nearExit[2], 'b--')\n",
    "    plt.title('near exit, moving right')\n",
    "    plt.subplot(222)    \n",
    "    plt.plot(x, leftSide[0], 'r--')\n",
    "    plt.plot(x, leftSide[1], 'g--')\n",
    "    plt.plot(x, leftSide[2], 'b--')\n",
    "    plt.title('left side, moving right')\n",
    "    plt.legend(('alpha = 1e-1', 'alpha = 1e-2', 'alpha = 1e-3'))\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "+ For the near exit moving right, we should get something close to -2.\n",
    "+ For the left side moving right, we should get aroung -39.\n",
    "\n",
    "#### State nearest to the exit and moving right\n",
    "The alpha of 0.001 produces the pretty bad estimates.\n",
    "It produces the non-physical result of approximately zero for the left side car. We shouldn't use that value.\n",
    "The alpha of 0.01 starts to move in the right direction. for the near-exit state, it actually starts to approach the true value of -2, but for the left side it seems to have stabilized at a value of about -5, which is again non-physical.\n",
    "The best seems to be alpha 0.1, that has an estimate of approximately -0.3 for the near exit and about -29 for the left side.\n",
    "\n",
    "#### Why so different from the Monte Carlo approximation?\n",
    "This is because the DT methods don't converge to the global minima. \n",
    "\n",
    "They find some other local minima nearby."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MLU Logo](https://drive.corp.amazon.com/view/bwernes@/MLU_Logo.png?download=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
